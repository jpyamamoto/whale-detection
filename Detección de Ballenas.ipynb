{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Detecci贸n Sonora de Ballenas Francas\n\n> Juan Pablo Yamamoto Zazueta  \n> [jpyamamoto@ciencias.unam.mx](mailto:jpyamamoto.ciencias.unam.mx)","metadata":{"tags":[]}},{"cell_type":"markdown","source":"## Instalaci贸n e inicializaci贸n de entorno","metadata":{"tags":[]}},{"cell_type":"markdown","source":"### Instalaci贸n de Dependencias","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"!pip install opendatasets","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:29:18.841336Z","iopub.execute_input":"2023-05-30T14:29:18.841807Z","iopub.status.idle":"2023-05-30T14:29:32.215146Z","shell.execute_reply.started":"2023-05-30T14:29:18.841765Z","shell.execute_reply":"2023-05-30T14:29:32.213798Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting opendatasets\n  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from opendatasets) (4.64.1)\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (from opendatasets) (1.5.13)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from opendatasets) (8.1.3)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (1.16.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (2023.5.7)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (2.8.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (2.28.2)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (8.0.1)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (1.26.15)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->opendatasets) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->opendatasets) (3.4)\nInstalling collected packages: opendatasets\nSuccessfully installed opendatasets-0.1.22\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install librosa","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:29:32.218883Z","iopub.execute_input":"2023-05-30T14:29:32.219204Z","iopub.status.idle":"2023-05-30T14:29:43.202959Z","shell.execute_reply.started":"2023-05-30T14:29:32.219176Z","shell.execute_reply":"2023-05-30T14:29:43.201848Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (0.10.0.post2)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa) (3.0.0)\nRequirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.23.5)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.10.1)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.2.0)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (5.1.1)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.56.4)\nRequirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.12.1)\nRequirement already satisfied: pooch<1.7,>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.6.0)\nRequirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.3.5)\nRequirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (4.5.0)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.2)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.0.5)\nRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.39.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (59.8.0)\nRequirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pooch<1.7,>=1.0->librosa) (21.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch<1.7,>=1.0->librosa) (2.28.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pooch<1.7,>=1.0->librosa) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2023.5.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install scipy","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:29:43.204401Z","iopub.execute_input":"2023-05-30T14:29:43.204806Z","iopub.status.idle":"2023-05-30T14:29:54.086782Z","shell.execute_reply.started":"2023-05-30T14:29:43.204767Z","shell.execute_reply":"2023-05-30T14:29:54.085408Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (1.10.1)\nRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scipy) (1.23.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch torchvision","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:29:54.089402Z","iopub.execute_input":"2023-05-30T14:29:54.089775Z","iopub.status.idle":"2023-05-30T14:30:05.421784Z","shell.execute_reply.started":"2023-05-30T14:29:54.089738Z","shell.execute_reply":"2023-05-30T14:30:05.420588Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.28.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"### Importar Dependencias","metadata":{"tags":[]}},{"cell_type":"code","source":"# Visualizaci贸n\n\nfrom IPython.display import Audio, display, HTML, IFrame, clear_output\nfrom ipywidgets import interact, widgets\nfrom matplotlib import pyplot as plt","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-05-30T14:30:05.424403Z","iopub.execute_input":"2023-05-30T14:30:05.424781Z","iopub.status.idle":"2023-05-30T14:30:05.513701Z","shell.execute_reply.started":"2023-05-30T14:30:05.424747Z","shell.execute_reply":"2023-05-30T14:30:05.512844Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Utilidades\n\nimport glob\nimport numpy as np\nimport os\nimport csv\nimport time","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:30:14.692228Z","iopub.execute_input":"2023-05-30T14:30:14.692778Z","iopub.status.idle":"2023-05-30T14:30:14.697732Z","shell.execute_reply.started":"2023-05-30T14:30:14.692744Z","shell.execute_reply":"2023-05-30T14:30:14.696509Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Herramientas\n\nimport opendatasets as od\nimport librosa\nfrom scipy.fft import fft\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:30:15.140266Z","iopub.execute_input":"2023-05-30T14:30:15.140939Z","iopub.status.idle":"2023-05-30T14:30:15.501673Z","shell.execute_reply.started":"2023-05-30T14:30:15.140905Z","shell.execute_reply":"2023-05-30T14:30:15.500780Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Red Neuronal\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom torchvision.ops.focal_loss import sigmoid_focal_loss","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-05-30T14:30:15.788341Z","iopub.execute_input":"2023-05-30T14:30:15.789448Z","iopub.status.idle":"2023-05-30T14:30:19.074209Z","shell.execute_reply.started":"2023-05-30T14:30:15.789408Z","shell.execute_reply":"2023-05-30T14:30:19.073240Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Preparaci贸n de los datos\n\nEl conjunto de datos fue desarrollado por Andr茅 Karpi拧t拧enko, Eric Spaulding y Will Cukierski, a trav茅s de Kaggle en la competencia [\"The Marinexplore and Cornell University Whale Detection Challenge\"](https://kaggle.com/competitions/whale-detection-challenge).\n\nPodemos descargarlo desde Kaggle utilizando la biblioteca `opendatasets`.","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"**Nota:** Primero dir铆gete al sitio web de la competencia ([https://www.kaggle.com/competitions/whale-detection-challenge/data](https://www.kaggle.com/competitions/whale-detection-challenge/data)) y acepta el aviso de Copyright para poder descargar el conjunto de datos.\n\nPosteriormente, descarga tus credenciales para usar la API de Kaggle en la configuraci贸n de tu perfil, y coloca el archivo `kaggle.json` en el mismo directorio de este archivo (para ser detectado autom谩ticamente) o copia y pega el contenido del archivo en la entrada que se desplegar谩 al ejecutar la siguiente celda.","metadata":{}},{"cell_type":"code","source":"od.download(\"https://www.kaggle.com/competitions/whale-detection-challenge/data\")","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Procedemos a organizar los archivos en que recibimos los datos, de manera que sean f谩cil de explorar.\n\nLa primera celda mueve los datos de ejemplo a la carpeta `sample`, y la segunda celda pone los archivos para entrenamiento y pruebas en la carpeta `data`.","metadata":{}},{"cell_type":"code","source":"%%capture\n# Capturamos la salida porque son demasiados archivos y ocupan mucho espacio en el notebook\n\n!unzip whale-detection-challenge/small_data_sample_revised.zip -d sample/\n!cp whale-detection-challenge/sample_submission.csv sample/\n!rm -r sample/__MACOSX\n!mv sample/small_data_sample/* sample/\n!rm -r sample/small_data_sample/","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n# Capturamos la salida porque son demasiados archivos y ocupan mucho espacio en el notebook\n\n!unzip whale-detection-challenge/whale_data.zip -d .","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"archivos_entrenamiento = glob.glob('./data/train/*.aiff')\narchivos_prueba = glob.glob('./data/test/*.aiff')\n\nprint(\"Archivos de entrenamiento: {}\".format(len(archivos_entrenamiento)))\nprint(\"Archivos de test: {}\".format(len(archivos_prueba)))","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Para manipular los archivos de audio que se encuentran en formato `.aiff`, vamos a utilizar la biblioteca [librosa](https://librosa.org/) que incluye varias herramientas relacionadas al procesamiento de audio.\n\nPodemos explorar algunos ejemplos de las grabaciones que tiene el conjunto con los archivos contenidos en el directorio `sample`:","metadata":{}},{"cell_type":"code","source":"archivos_no_whale = glob.glob('./sample/no_right_whale/*.aiff')\nsamples_no_whale = [librosa.load(file, sr=None) for file in archivos_no_whale]\n\narchivos_whale = glob.glob('./sample/right_whale/*.aiff')\nsamples_whale = [librosa.load(file, sr=None) for file in archivos_whale]","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"no_whale, samplerate_nw = librosa.load('./sample/no_right_whale/train1.aiff')\nwhale, samplerate_w = librosa.load('./sample/right_whale/train9.aiff')\n\nprint(\"No whale:\")\ndisplay(Audio(no_whale, rate=samplerate_nw))\nprint(\"Whale:\")\ndisplay(Audio(whale, rate=samplerate_w))","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Todos los audios cumplen con las siguientes especificaciones:\n\n- Duraci贸n: 2 segundos\n- Frecuencia de muestreo: 2 kHz\n\nDebemos tener cuidado al utilizar la biblioteca `librosa`, pues por defecto va a hacer un resampling.","metadata":{}},{"cell_type":"code","source":"_, samplerate_original = samples_no_whale[0]\n_, samplerate_default = librosa.load('./sample/no_right_whale/train1.aiff')\n\nprint(\"Frecuencia de muestreo original: {} Hz\".format(samplerate_original))\nprint(\"Frecuencia de muestreo por defecto: {} Hz\".format(samplerate_default))","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## An谩lisis de los datos","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"Primero que nada, para poder procesar datos de audio tenemos que entender la forma en que se representa el audio digitalmente.\n\nLo que un micr贸fono har铆a es medir la presi贸n relativa que ejerce el medio (normalmente aire, pero en nuestro caso el medio ser铆a agua) sobre el dispositivo de captura. De manera tal que una mayor presi贸n representa una onda enviada a trav茅s del medio con mayor fuerza.\n\nPor otro lado, esta presi贸n al ser en realidad la medici贸n de ondas, tiene otra propiedad: la frecuencia. Cuando vemos la representaci贸n de una onda, seg煤n la cercan铆a de dos crestas de la onda es la frecuencia del sonido que escuchamos.\n\nSi bien esta presi贸n en el mundo real se considera una funci贸n continua, para trabajar con ella digitalmente, tenemos que discretizarla. Para esto se toman muestras en intervalos de tiempo bien definidos, y se redondean a un valor representable seg煤n la precisi贸n con que cuenta la computadora.\n\nEsta es, a grandes rasgos, la manera en que se almacena audio de forma digital. Esto nos lleva a la primera visualizaci贸n que podemos hacer de los datos que tenemos, y es la visualizaci贸n por amplitud de onda:","metadata":{"tags":[]}},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 9))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Amplitud de Onda: Sin Ballenas')\n\nfor ax, sample in zip(plots, samples_no_whale):\n    audio = sample[0]\n    ax.plot(audio)\n    ax.set_xlim([0, audio.shape[0]])\n    ax.set_ylim([-0.1, 0.1])\n    ax.set_xlabel('Muestra')\n    ax.set_ylabel('Amplitud')\n    \nax6.axis('off');","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 9))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Amplitud de Onda: Con Ballenas')\n\nfor ax, sample in zip(plots, samples_whale):\n    audio = sample[0]\n    ax.plot(audio)\n    ax.set_xlim([0, audio.shape[0]])\n    ax.set_ylim([-0.1, 0.1])\n    ax.set_xlabel('Muestra')\n    ax.set_ylabel('Amplitud')\n    \nax6.axis('off');","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como mencionamos anteriormente, la frecuencia de un sonido depende de la cercan铆a entre dos crestas de la onda medida. Por otro lado, al discretizar la onda, 煤nicamente podemos tomar medidas cada cierto intervalo de tiempo. Esto quiere decir que ciertas frecuencias requieren mayor cantidad de mediciones para ser capturadas apropiadamente, y otras requieren menos.\n\nLa medida de cu谩ntas muestras debemos tomar para poder recuperar de manera apropiada la frecuencia grabada en un audio, es la [frecuencia Nyquist](https://mathworld.wolfram.com/NyquistFrequency.html), la cu谩l indica lo siguiente:\n\nLa mayor frecuencia $f_{\\text{Nyquist}}$ que puede ser capturada con una tasa de muestreo $v$, es $f(v)=\\dfrac{1}{2}v$.\n\nEso nos da una primera pista sobre nuestros datos: si la frecuencia de muestreo es de 2 kHz, eso quiere decir que la m谩xima frecuencia registrada en el sonido puede ser de 1 kHz.","metadata":{}},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 9))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Densidad Espectral: Sin Ballenas')\n\nfor ax, sample in zip(plots, samples_no_whale):\n    audio, sr = sample\n    X = fft(audio)\n    f = np.linspace(0, sr, len(X))\n    ax.plot(f, X)\n    ax.set_xlim([0, f.shape[0]/2])\n    ax.set_xlabel('Frecuencia (Hz)')\n    ax.set_ylabel('Magnitud')\n    \nax6.axis('off');","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 9))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Densidad Espectral: Con Ballenas')\n\nfor ax, sample in zip(plots, samples_whale):\n    audio, sr = sample\n    X = fft(audio)\n    f = np.linspace(0, sr, len(X))\n    ax.plot(f, X)\n    ax.set_xlim([0, f.shape[0]/2])\n    ax.set_xlabel('Frecuencia (Hz)')\n    ax.set_ylabel('Magnitud')\n    \nax6.axis('off');","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos ver en los ejemplos que efectivamente, las frecuencias capturadas se encuentran entre 0 y 1000 Hz. Tenemos valores hasta 2 kHz por la forma en que funciona la transformada de Fourier, que refleja los resultados sobre la frecuencia de Nyquist (en nuestro caso, recordemos que era 1000).\n\nSin embargo, esto sigue sin darnos suficiente informaci贸n para detectar el sonido de las ballenas. Notemos que las gr谩ficas son bastante parecidas en ambas categor铆as, a excepci贸n de algunos casos donde las grabaciones con ballenas parecen tener magnitudes m谩s grandes.\n\nSin embargo, no podemos confiar en esto, pues no sabemos si esas frecuencias son causadas por las ballenas o por cualquier otro factor en la grabaci贸n.","metadata":{}},{"cell_type":"markdown","source":"## Conociendo a las Ballenas","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"Investigando m谩s sobre las ballenas francas y los sonidos que hacen, encontramos los siguientes datos relevantes:\n\n- Producen 3 tipos de sonidos: gemidos, quejidos y eruptos.\n- La mayor铆a de los sonidos que producen se mantienen por debajo de los 500 Hz.\n- Pocas veces emiten sonidos que alcanzan hasta los 4 kHz.\n- El sonido distintivo de las ballenas francas es el \"whoop\" o \"up call\":\n    - Sube de los 50 Hz a los 440 Hz.\n    - Dura alrededor de 2 segundos.\n    - Se utiliza para llamar a otras ballenas francas y generalmente las atrae a reunirse.\n    - Es un sonido que emiten de manera constante y com煤n.\n    - Es el sonido m谩s com煤nmente utilizado por los expertos para identificar ballenas francas.\n    \nDe los datos anteriores, considero que la mejor v铆a para detectar a las ballenas es usando el sonido \"whoop\", confiando en lo que hacen los expertos. Esto nos ayuda a identificar qu茅 tipo de patrones buscar:\n- Incremento en la frecuencia.\n- Comienza cerca de 50 Hz y sube cerca de 440 Hz.\n- Presente en la duraci贸n de la grabaci贸n.","metadata":{}},{"cell_type":"markdown","source":"A continuaci贸n podemos ver una grabaci贸n donde se escucha el sonido \"whoop\". Una grabaci贸n m谩s clara de este sonido se escucha en el siguiente video que no podemos incrustar en el notebook por restricciones impuestas por la plataforma donde se public贸: [North Atlantic Right Whale \"up call\"](https://vimeo.com/227009627).","metadata":{}},{"cell_type":"code","source":"IFrame(src=\"https://www.youtube.com/embed/1WFnX4zO9GU\", height=315, width=560)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos ver en los videos que se est谩n usando espectrogramas para visualizar las frecuencias del sonido, y en ambos vemos unas curvas convexas.\n\nEsto concuerda con la imagen provista en la p谩gina del concurso, distinguiendo el sonido de la ballena franca:\n\n![Imagen Espectrograma](https://storage.googleapis.com/kaggle-competitions/kaggle/3353/media/whale_detection_challenge-cwc-es.png)","metadata":{}},{"cell_type":"markdown","source":"Si bien la visualizaci贸n de amplitud de onda nos puede dar una idea de qu茅 frecuencias colaboran a la onda durante los 2 segundos de grabaci贸n, no es suficiente conocer que hay sonidos en las frecuencias 50 - 440 kHz. Tambi茅n necesitamos saber que siguen el patr贸n ascendente. De otra manera podr铆a ser que hay otros factores generando sonidos en esas frecuencias, sin estar relacionados.\n\nPor lo tanto, tenemos que visualizar las frecuencias no s贸lo por su contribuci贸n a la onda total, sino considerando tambi茅n su magnitud en el tiempo. Para ello vamos a utilizar los **espectrogramas**.","metadata":{}},{"cell_type":"markdown","source":"## Espectrogramas","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"Para visualizar las frecuencias que componen una onda a trav茅s del dominio del tiempo, podemos usar espectrogramas. Estos van a descomponer la onda en sus frecuencias, en una cierta ventana de tiempo. Luego, va a utilizar c贸digos de color para mostrar la intensidad en decibelios de una cierta frecuencia en cada intervalo.\n\nPodemos visualizarlo de la siguiente manera:","metadata":{}},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 15))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Frecuencias: Sin Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_no_whale):\n    audio, sr = sample\n    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n    img = librosa.display.specshow(D, y_axis='linear', x_axis='time', sr=sr, ax=ax)\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 15))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Frecuencias: Con Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_whale):\n    audio, sr = sample\n    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n    img = librosa.display.specshow(D, y_axis='linear', x_axis='time', sr=sr, ax=ax)\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como podemos ver, los espectrogramas contienen demasiada informaci贸n en un comienzo, y no son precisamente informativos. Vamos a intentar limpiar un poco m谩s los datos para ser capaces de extraer la informaci贸n relevante a nuestro problema.\n\nUna primera mejora que podemos intentar aplicar es 煤nicamente considerar las frecuencias en el rango 0 Hz - 500 Hz. Esto es porque, como vimos antes, es el rango de frecuencias que emiten las ballenas.","metadata":{}},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Frecuencias: Sin Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_no_whale):\n    audio, sr = sample\n    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n    img = librosa.display.specshow(D, y_axis='linear', x_axis='time', sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Frecuencias: Con Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_whale):\n    audio, sr = sample\n    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n    img = librosa.display.specshow(D, y_axis='linear', x_axis='time', sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ahora estamos limitando los espectrogramas a frecuencias hasta los 500 Hz. Igualmente notemos que los intervalos de tiempo son demasiado amplios. Si contamos las divisiones verticales, encontramos que solo hay 8 ventanas de tiempo en las que estamos midiendo las frecuencias.\n\nEl algoritmo que utilizamos (Short Time Fourier Transform) requiere que indiquemos los siguientes par谩metros:\n- Tama帽o del intervalo: La cantidad de muestras que se van a considerar en la ventana a la que se aplica la transformada de Fourier.\n- Tama帽o del salto: La cantidad de muestras a desplazarnos entre una ventana de tiempo y la siguiente.\n\nEn realidad no hay una medida concreta sobre qu茅 valores deben tomar esas variables. Mediante prueba y error (podemos hacer la prueba en la siguiente celda) encontramos valores que nos convencieron pues parecen entregar im谩genes descriptivas, sin ser de un tama帽o no manejable.\n","metadata":{}},{"cell_type":"code","source":"@interact(\n    frame_size = widgets.IntSlider(min=10, max=500, step=1, value=256),\n)\ndef visualize_stft(frame_size):\n    fig, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(12, 4))\n    \n    hop_length = frame_size // 4\n\n    fig.suptitle('Espectrograma (Intervalo: {}, Salto: {})'.format(frame_size, hop_length))\n\n    audio_nw, sr_nw = samples_no_whale[4]\n    audio_w, sr_w = samples_whale[4]\n    \n    D_nw = librosa.amplitude_to_db(np.abs(librosa.stft(audio_nw, hop_length=hop_length, n_fft=frame_size)), ref=np.max)\n    img = librosa.display.specshow(D_nw, y_axis='linear', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr_nw, ax=ax1)\n    \n    D_w = librosa.amplitude_to_db(np.abs(librosa.stft(audio_w, hop_length=hop_length, n_fft=frame_size)), ref=np.max)\n    img = librosa.display.specshow(D_w, y_axis='linear', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr_w, ax=ax2)\n    \n    ax1.set_ylim([0, 500])\n    ax1.set_xlabel('Tiempo (segundos)')\n    ax1.set_ylabel('Frecuencia')\n    ax1.set_title('Sin Ballena')\n    \n    ax2.set_ylim([0, 500])\n    ax2.set_xlabel('Tiempo (segundos)')\n    ax2.set_ylabel('Frecuencia')\n    ax2.set_title('Con Ballena')\n    \n    fig.subplots_adjust(right=0.8)\n    cbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\n    fig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Algunos consejos para seleccionar esos valores, que encontramos son los siguientes:\n- Que el tama帽o del intervalo sea una potencia de 2.\n- Que el tama帽o del salto sea una cuarta parte del tama帽o del intervalo.\n\nPor ello, habiendo encontrado valores que nos convencieron en la celda anterior, redondeamos el tama帽o del intervalo a la potencia de 2 m谩s cercana y dimos el tama帽o del salto una cuarta parte de este.\n\nEsto nos dio los siguientes valores:","metadata":{}},{"cell_type":"code","source":"frame_size = 256\nhop_length = frame_size // 4\n\nprint(\"Tama帽o del intervalo: {}\".format(frame_size))\nprint(\"Tama帽o del salto: {}\".format(hop_length))","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Frecuencias: Sin Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_no_whale):\n    audio, sr = sample\n    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio, hop_length=hop_length, n_fft=frame_size)), ref=np.max)\n    img = librosa.display.specshow(D, y_axis='linear', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Frecuencias: Con Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_whale):\n    audio, sr = sample\n    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio, hop_length=hop_length, n_fft=frame_size)), ref=np.max)\n    img = librosa.display.specshow(D, y_axis='linear', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Espectrogramas de Mel","metadata":{}},{"cell_type":"markdown","source":"Hay un 煤ltimo hecho que queremos tomar en cuenta al momento de generar los espectrogramas. Esto es que los humanos (y en general los animales) no percibimos el sonido de forma lineal. Es decir, al reproducir dos frecuencias a un intervalo dado y luego reproducir dos notas al mismo intervalo en una frecuencia distinta (y asumamos que lejana), percibiremos claramente que un par suena m谩s parecido que el otro.\n\nEsto se debe a que el sonido se percibe de forma logar铆tmica. Mientras mayor es la frecuencia, m谩s lejanas deben estar dos frecuencias para que el intervalo entre ellas se **perciba** como constante.\n\nPuesto que esto es algo generalizado en los animales, podemos asumir que las ballenas tambi茅n perciben de esta manera el sonido. Y por lo mismo parece apropiado asumir que la forma de analizar el sonido emitido por ellas debe ajustarse a esta m茅trica.\n\nPara ello vamos a utilizar los espectrogramas de Mel.\n\nEn la imagen siguiente podemos visualizar c贸mo funciona el filtro que ser谩 aplicado a la imagen. Podemos ver que seg煤n la frecuencia del sonido, ser谩 la intensidad del filtro que se aplique.\n\nLa tasa de muestreo al ser baja (recordemos que era de 200), no permite visualizar tan claramente la forma logar铆tmica que tiene este filtro, debido a que son pocas las frecuencias alcanzables. Pero podemos hacer el experimento de incrementar la variable `sr` a un valor como `22050` (la tasa de muestreo est谩ndar para archivos de m煤sica) y va a ser clara la diferencia.","metadata":{}},{"cell_type":"code","source":"@interact(\n    mel_bands = widgets.IntSlider(min=5, max=50, step=1, value=10),\n)\ndef visualize_stft(mel_bands):\n    fig, ax = plt.subplots()\n    sr = 200\n    filter_banks = librosa.filters.mel(n_fft=frame_size, sr=sr, n_mels=mel_bands)\n    librosa.display.specshow(filter_banks, sr=sr, x_axis='linear')\n    fig.colorbar(img, ax=ax, format='%+2.0f dB')\n    ax.set(title='Espectrograma de los filtros de Mel')","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vamos a buscar el n煤mero apropiado de bandas de Mel para nuestro caso de uso. No encontr茅 alguna f贸rmula o heur铆stica para determinar este valor, sino que m谩s bien la elecci贸n debe ir guiada por la resoluci贸n que da (y lo que esperamos ver en la imagen).\n\nEn la siguiente celda podemos experimentar con el valor que consideramos da un buen resultado.","metadata":{}},{"cell_type":"code","source":"@interact(\n    mel_bands = widgets.IntSlider(min=10, max=200, step=1, value=128),\n)\ndef visualize_stft(mel_bands):\n    fig, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(12, 4))\n    \n    fig.suptitle('Espectrograma (Bandas de Mel: {})'.format(mel_bands))\n\n    audio_nw, sr_nw = samples_no_whale[4]\n    audio_w, sr_w = samples_whale[4]\n    \n    mel_spec_nw = librosa.feature.melspectrogram(y=audio_nw, sr=sr_nw, n_fft=frame_size, hop_length=hop_length, n_mels=mel_bands)\n    mel_spec_w = librosa.feature.melspectrogram(y=audio_w, sr=sr_w, n_fft=frame_size, hop_length=hop_length, n_mels=mel_bands)\n    \n    D_nw = librosa.power_to_db(mel_spec_nw, ref=np.max)\n    img = librosa.display.specshow(D_nw, y_axis='mel', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr_nw, ax=ax1)\n    \n    D_w = librosa.power_to_db(mel_spec_w, ref=np.max)\n    img = librosa.display.specshow(D_w, y_axis='mel', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr_w, ax=ax2)\n    \n    ax1.set_ylim([0, 500])\n    ax1.set_xlabel('Tiempo (segundos)')\n    ax1.set_ylabel('Frecuencia')\n    ax1.set_title('Sin Ballena')\n    \n    ax2.set_ylim([0, 500])\n    ax2.set_xlabel('Tiempo (segundos)')\n    ax2.set_ylabel('Frecuencia')\n    ax2.set_title('Con Ballena')\n    \n    fig.subplots_adjust(right=0.8)\n    cbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\n    fig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El valor que nos convenci贸 fue el de la siguiente celda.\n\n- Con valores m谩s grandes, parece haber mucho ruido en la imagen.\n- Con valores m谩s peque帽os se desvanecen algunos colores y perdemos informaci贸n.","metadata":{}},{"cell_type":"code","source":"mel_bands = 128\n\nprint(\"Bandas de Mel: {}\".format(mel_bands))","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Mel: Sin Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_no_whale):\n    audio, sr = sample\n    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=frame_size, hop_length=hop_length, n_mels=mel_bands)\n    D = librosa.power_to_db(mel_spec, ref=np.max)\n    img = librosa.display.specshow(D, y_axis='mel', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Mel: Con Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_whale):\n    audio, sr = sample\n    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=frame_size, hop_length=hop_length, n_mels=mel_bands)\n    D = librosa.power_to_db(mel_spec, ref=np.max)\n    img = librosa.display.specshow(D, y_axis='mel', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finalmente, notemos que la forma en que utilizamos la escala de colores es lineal. Si bien para un humano es m谩s f谩cil visualizar la intensidad por colores, la computadora lo va a leer como n煤meros de mayor o menor tama帽o.\n\nPor lo tanto, podemos convertir la imagen a escala de grises para facilitar su procesamiento por la red neuronal.","metadata":{}},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Mel: Sin Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_no_whale):\n    audio, sr = sample\n    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=frame_size, hop_length=hop_length, n_mels=mel_bands)\n    D = librosa.power_to_db(mel_spec, ref=np.max)\n    img = librosa.display.specshow(D, cmap='gray', y_axis='mel', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Mel: Con Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_whale):\n    audio, sr = sample\n    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=frame_size, hop_length=hop_length, n_mels=mel_bands)\n    D = librosa.power_to_db(mel_spec, ref=np.max)\n    img = librosa.display.specshow(D, cmap='gray', y_axis='mel', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Procesamiento de las im谩genes","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Tras haber determinado la forma en que convertiremos los archivos de audio a im谩genes, y encontrando la configuraci贸n adecuada, vamos a procesar los archivos para poder utilizarlos con la red neuronal.","metadata":{}},{"cell_type":"code","source":"def audio_to_img(audio, sr):\n    img = librosa.feature.melspectrogram(y=audio,\n                                         sr=sr,\n                                         n_fft=frame_size,\n                                         hop_length=hop_length,\n                                         n_mels=mel_bands)\n   \n    img = librosa.power_to_db(img, ref=np.max)\n    img = np.flip(img, axis=0)\n    img = np.c_[ img[64:], np.ones(64)] # Imagen cuadrada\n    \n    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n    img = img * 255\n    \n    img = img.astype(np.uint8)\n    img = Image.fromarray(img)\n\n    return img\n\ndef convert_audio_file(file, output):\n    audio, sr = librosa.load(file, sr=None)\n    img = audio_to_img(audio, sr)\n    img.save(output, format='PNG', optimize=False, compress_level=0)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_labels = dict()\n\nwith open('./data/train.csv', 'r') as data:\n    next(data)\n    \n    for row in csv.reader(data, delimiter=','):\n        training_labels[row[0]] = int(row[1])","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Primero convertimos los archivos de audio para entrenamiento a im谩genes `png` sin compresi贸n ni perdida. Los colocaremos en los directorios:\n- `./data_img/train/negative`: Si tiene etiqueta negativa (no hay ballena presente).\n- `./data_img/train/positive`: Si tiene etiqueta positiva (s铆 hay ballena presente).","metadata":{}},{"cell_type":"code","source":"!mkdir -p data_img/train/negative\n!mkdir -p data_img/train/positive","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = './data_img/train/'\n\nsubpath = ['negative/', 'positive/']\n\ni = 1\ntotal = len(archivos_entrenamiento)\n\nfor file in archivos_entrenamiento:\n    filename = os.path.basename(file)\n    file_noext = os.path.splitext(filename)[0]\n    \n    label = training_labels[filename]\n    output_filename = base_path + subpath[label] + file_noext + '.png'\n    \n    clear_output(wait=True)\n    print('Convirtiendo archivo {} a {}\\nArchivo {}/{}'.format(filename, file_noext + '.png', i, total))\n    \n    convert_audio_file(file, output_filename)\n    i += 1\n    \nprint(\"Completado.\")","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tambi茅n convertimos los archivos de audio del conjunto de prueba.\n\nEstar谩n en el directorio `./data_img/test/`.","metadata":{}},{"cell_type":"code","source":"!mkdir -p data_img/test/","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = './data_img/test/'\n\ni = 1\ntotal = len(archivos_prueba)\n\nfor file in archivos_prueba:\n    filename = os.path.basename(file)\n    file_noext = os.path.splitext(filename)[0]\n    \n    output_filename = base_path + file_noext + '.png'\n    \n    clear_output(wait=True)\n    print('Convirtiendo archivo {} a {}\\nArchivo {}/{}'.format(filename, file_noext + '.png', i, total))\n    \n    convert_audio_file(file, output_filename)\n    i += 1\n    \nprint(\"Completado.\")","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Habiendo convertido todas las im谩genes, tenemos los siguientes conjuntos de datos.","metadata":{}},{"cell_type":"code","source":"img_train_neg = glob.glob('/kaggle/input/whale/data_img/train/negative/*.png')\nimg_train_pos = glob.glob('/kaggle/input/whale/data_img/train/positive/*.png')\nimg_test = glob.glob('/kaggle/input/whale/data_img/test/*.png')\n\nprint(\"Im谩genes de prueba: {}\".format(len(img_test)))\nprint(\"Im谩genes de entrenamiento (categor铆a positiva): {}\".format(len(img_train_pos)))\nprint(\"Im谩genes de entrenamiento (categor铆a negativa): {}\".format(len(img_train_neg)))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-05-30T14:31:55.796475Z","iopub.execute_input":"2023-05-30T14:31:55.796868Z","iopub.status.idle":"2023-05-30T14:31:57.004651Z","shell.execute_reply.started":"2023-05-30T14:31:55.796839Z","shell.execute_reply":"2023-05-30T14:31:57.003711Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Im谩genes de prueba: 54503\nIm谩genes de entrenamiento (categor铆a positiva): 7027\nIm谩genes de entrenamiento (categor铆a negativa): 22973\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### DataSets y DataLoaders","metadata":{}},{"cell_type":"markdown","source":"Vamos a crear una clase para un Dataset que tome los datos de las im谩genes de ballenas y las clasifique con su etiqueta correspondiente.","metadata":{}},{"cell_type":"code","source":"class WhaleSpectrogramsDataset(Dataset):\n    def __init__(self, positive_paths, negative_paths, transform=None, target_transform=None):\n        self.imgs = list(map(lambda p: (1, p), positive_paths)) + list(map(lambda p: (0, p), negative_paths))\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.imgs)\n\n    def __getitem__(self, idx):\n        label, img_path = self.imgs[idx]\n        image = Image.open(img_path)\n        \n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n            \n        return image, label","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-05-30T14:32:01.981082Z","iopub.execute_input":"2023-05-30T14:32:01.981479Z","iopub.status.idle":"2023-05-30T14:32:01.992475Z","shell.execute_reply.started":"2023-05-30T14:32:01.981447Z","shell.execute_reply":"2023-05-30T14:32:01.991251Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Con lo anterior, podemos crear nuestros conjuntos de datos.\n\nPara el dataset de prueba, vamos a ignorar las etiquetas entonces las tomamos como clasificadas indistintamente.","metadata":{}},{"cell_type":"code","source":"train_dataset = WhaleSpectrogramsDataset(positive_paths=img_train_pos,\n                                         negative_paths=img_train_neg,\n                                         transform=transforms.Compose([\n                                             transforms.Resize((227,227)),\n                                             transforms.ToTensor(),\n                                             transforms.Normalize([0.5], [0.5])\n                                         ]),\n                                         target_transform=torch.tensor)\n\nmid = len(img_test) // 2\ntest_dataset = WhaleSpectrogramsDataset(positive_paths=img_test[:mid],\n                                        negative_paths=img_test[mid:],\n                                        transform=transforms.Compose([\n                                            transforms.Resize((227,227)),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize([0.5], [0.5])\n                                        ]),\n                                        target_transform=torch.tensor)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-05-30T14:32:03.948779Z","iopub.execute_input":"2023-05-30T14:32:03.949496Z","iopub.status.idle":"2023-05-30T14:32:03.981757Z","shell.execute_reply.started":"2023-05-30T14:32:03.949461Z","shell.execute_reply":"2023-05-30T14:32:03.980767Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Con los datasets anteriores, podemos crear un Dataloader que divida los datos en batches de cierto tama帽o para el entrenamiento. Vamos a utilizar batches de tama帽o 1, ","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, shuffle=True,  num_workers=2)\ntest_loader  = DataLoader(test_dataset,  shuffle=False, num_workers=2)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-05-30T14:32:06.040529Z","iopub.execute_input":"2023-05-30T14:32:06.040900Z","iopub.status.idle":"2023-05-30T14:32:06.047197Z","shell.execute_reply.started":"2023-05-30T14:32:06.040869Z","shell.execute_reply":"2023-05-30T14:32:06.045834Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Red Neuronal","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Para la red neuronal, nos estaremos basando en la arquitectura de AlexNet.\n\nEsta fue introducida por primera vez en el art铆culo [\"ImageNet Classification with Deep Convolutional\nNeural Networks\"](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) escrito por Alex Krizhevsky, Ilya Sutskever y Geoffrey E. Hinton. Se utiliz贸 en la competencia ImageNet del 2012, obteniendo muy buenos resultados.\n\nPrincipalmente se utiliza para im谩genes de tama帽o 227x227, con 3 canales de color. Sin embargo, veremos que podemos adecuarla a nuestro caso de uso.\n\nLa arquitectura es la siguiente (imagen de [Paras Varshney](https://github.com/blurred-machine)):\n\n![Arquitectura AlexNet](https://raw.githubusercontent.com/blurred-machine/Data-Science/master/Deep%20Learning%20SOTA/img/alexnet2.png)\n\nLa imagen omite algunos detalles como lo son las capas DropOut y las activaciones ReLU, pero en la implementaci贸n tenemos cuidado de incluirlas.","metadata":{}},{"cell_type":"code","source":"class Red(nn.Module):\n    def __init__(self, num_classes):\n        super(Red, self).__init__()\n        \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2)\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2)\n        )\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n        self.conv4 = nn.Sequential(\n            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n        self.conv5 = nn.Sequential(\n            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2)\n        )\n        self.flatten = nn.Flatten(start_dim=1)\n        self.fc1 = nn.Sequential(\n            nn.Dropout(p=0.5),\n            nn.Linear(in_features=256*6*6, out_features=4096),\n            nn.ReLU()\n        )\n        self.fc2 = nn.Sequential(\n            nn.Dropout(p=0.5),\n            nn.Linear(in_features=4096, out_features=4096),\n            nn.ReLU()\n        )\n        self.fc3 = nn.Sequential(\n            nn.Linear(in_features=4096, out_features=num_classes),\n            nn.Softmax(dim=1)\n        )\n        \n    def forward(self, x, single=False):\n        if single:\n            x = x[None,:]\n        \n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        x = self.fc3(x)\n        \n        return x\n    \n    def train(self, epochs, data_loader, criterion, optimizer, device=None, debug=False, save_dir=None):\n        error = np.zeros(epochs)\n        \n        for epoch in range(epochs):\n            running_loss = 0.0\n            start_time = time.time()\n            i = 0\n            \n            for input_data, label in data_loader:\n                i += 1\n                optimizer.zero_grad()\n                \n                if device:\n                    input_data = input_data.to(device)\n                    label = label.to(device)\n                \n                output = self(input_data)\n                loss = criterion(output, label)\n                \n                loss.backward()\n                optimizer.step()\n                \n                running_loss += loss.item()\n                \n            error[epoch] = running_loss\n            end_time = time.time()\n            \n            if debug:\n                print('-'*40)\n                print('Epoch: {}\\nElapsed Time: {:0.2f} minutes\\nError: {}\\nAverage Error: {}'.format(epoch, (end_time - start_time) / 60, running_loss, running_loss / i))\n            \n            if save_dir:\n                filename = os.path.join(save_dir, 'model_{}.pt'.format(epoch))\n                torch.save(self.state_dict(), filename)\n            \n        plt.plot(error)\n        plt.xlabel('epoch')\n        plt.ylabel('error');","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:32:11.457675Z","iopub.execute_input":"2023-05-30T14:32:11.458069Z","iopub.status.idle":"2023-05-30T14:32:11.477789Z","shell.execute_reply.started":"2023-05-30T14:32:11.458040Z","shell.execute_reply":"2023-05-30T14:32:11.476670Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Para el entrenamiento, vamos a utilizar una funci贸n de p茅rdida llamada Focal Loss.\n\nEsta es una mejora a la entrop铆a cruzada, que sabemos es de las mejores opciones cuando tenemos tareas de clasificaci贸n. Sin embargo, la p茅rdida focal va a permitir adaptarse mejor a aquellos casos que la red a煤n no aprende bien, en vez de poner toda su atenci贸n en los casos ya aprendidos.\n\nEsto es 煤til cuando el conjunto de datos de entrada no es del todo balanceado, como es nuestro caso en donde tenemos casi el triple de ejemplares de una categor铆a.\n\nEl optimizador a utilizar en nuestro caso ser谩 Adam. La elecci贸n se basa simplemente en que, en nuestra experiencia a lo largo del curso, este tiende a comportarse bien.","metadata":{}},{"cell_type":"code","source":"red = Red(num_classes=2)\n\ncriterion = lambda output, label: sigmoid_focal_loss(output, F.one_hot(label, num_classes=2).to(torch.float), reduction='mean')\ncriterion = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(red.parameters(), lr=0.001)\noptimizer = optim.SGD(red.parameters(), lr=0.005)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:33:50.160667Z","iopub.execute_input":"2023-05-30T14:33:50.161230Z","iopub.status.idle":"2023-05-30T14:33:50.632575Z","shell.execute_reply.started":"2023-05-30T14:33:50.161198Z","shell.execute_reply":"2023-05-30T14:33:50.631613Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Vamos a configurar CUDA cuando se encuentre disponible.","metadata":{}},{"cell_type":"code","source":"cuda = torch.cuda.is_available()\nprint(\"CUDA disponible:\", cuda)\n\nif cuda:\n    # Descomentar y cambiar el dispositivo, en caso de desearlo.\n    # torch.cuda.set_device(1)\n    \n    cuda_id = torch.cuda.current_device()\n    print(\"Dispositivo CUDA:\", torch.cuda.get_device_name(cuda_id))\n    \ndevice = torch.device('cuda' if cuda else 'cpu')\n\nred.to(device)\n\nprint(\"Utilizando:\", device)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-05-30T14:33:51.991985Z","iopub.execute_input":"2023-05-30T14:33:51.992382Z","iopub.status.idle":"2023-05-30T14:33:52.067491Z","shell.execute_reply.started":"2023-05-30T14:33:51.992324Z","shell.execute_reply":"2023-05-30T14:33:52.066378Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"CUDA disponible: True\nDispositivo CUDA: Tesla P100-PCIE-16GB\nUtilizando: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"red.train(epochs=30, data_loader=train_loader, criterion=criterion, optimizer=optimizer, device=device, debug=True, save_dir='/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:33:53.600511Z","iopub.execute_input":"2023-05-30T14:33:53.600874Z","iopub.status.idle":"2023-05-30T16:37:31.227867Z","shell.execute_reply.started":"2023-05-30T14:33:53.600838Z","shell.execute_reply":"2023-05-30T16:37:31.226852Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"----------------------------------------\nEpoch: 0\nElapsed Time: 3.87 minutes\nError: 16492.117018669844\nAverage Error: 0.5497372339556614\n----------------------------------------\nEpoch: 1\nElapsed Time: 4.02 minutes\nError: 16424.972415864468\nAverage Error: 0.5474990805288156\n----------------------------------------\nEpoch: 2\nElapsed Time: 4.01 minutes\nError: 16424.909214287996\nAverage Error: 0.5474969738095998\n----------------------------------------\nEpoch: 3\nElapsed Time: 4.05 minutes\nError: 16424.888523072004\nAverage Error: 0.5474962841024001\n----------------------------------------\nEpoch: 4\nElapsed Time: 4.34 minutes\nError: 16424.87847533822\nAverage Error: 0.5474959491779406\n----------------------------------------\nEpoch: 5\nElapsed Time: 4.49 minutes\nError: 16424.872795671225\nAverage Error: 0.5474957598557075\n----------------------------------------\nEpoch: 6\nElapsed Time: 4.14 minutes\nError: 16424.86837208271\nAverage Error: 0.547495612402757\n----------------------------------------\nEpoch: 7\nElapsed Time: 4.14 minutes\nError: 16424.866963922977\nAverage Error: 0.5474955654640993\n----------------------------------------\nEpoch: 8\nElapsed Time: 4.13 minutes\nError: 16424.864463955164\nAverage Error: 0.5474954821318389\n----------------------------------------\nEpoch: 9\nElapsed Time: 4.08 minutes\nError: 16424.863263249397\nAverage Error: 0.5474954421083132\n----------------------------------------\nEpoch: 10\nElapsed Time: 4.08 minutes\nError: 16424.860868632793\nAverage Error: 0.5474953622877597\n----------------------------------------\nEpoch: 11\nElapsed Time: 4.07 minutes\nError: 16424.86068561673\nAverage Error: 0.5474953561872243\n----------------------------------------\nEpoch: 12\nElapsed Time: 4.07 minutes\nError: 16424.85982069373\nAverage Error: 0.5474953273564577\n----------------------------------------\nEpoch: 13\nElapsed Time: 4.06 minutes\nError: 16424.8589682281\nAverage Error: 0.5474952989409367\n----------------------------------------\nEpoch: 14\nElapsed Time: 4.08 minutes\nError: 16424.85857564211\nAverage Error: 0.547495285854737\n----------------------------------------\nEpoch: 15\nElapsed Time: 4.14 minutes\nError: 16424.858139634132\nAverage Error: 0.5474952713211377\n----------------------------------------\nEpoch: 16\nElapsed Time: 4.11 minutes\nError: 16424.857522547245\nAverage Error: 0.5474952507515748\n----------------------------------------\nEpoch: 17\nElapsed Time: 4.12 minutes\nError: 16424.857431054115\nAverage Error: 0.5474952477018038\n----------------------------------------\nEpoch: 18\nElapsed Time: 4.13 minutes\nError: 16424.857038140297\nAverage Error: 0.5474952346046765\n----------------------------------------\nEpoch: 19\nElapsed Time: 4.14 minutes\nError: 16424.85689085722\nAverage Error: 0.5474952296952407\n----------------------------------------\nEpoch: 20\nElapsed Time: 4.12 minutes\nError: 16424.85614231229\nAverage Error: 0.5474952047437429\n----------------------------------------\nEpoch: 21\nElapsed Time: 4.13 minutes\nError: 16424.85620048642\nAverage Error: 0.5474952066828808\n----------------------------------------\nEpoch: 22\nElapsed Time: 4.14 minutes\nError: 16424.85603222251\nAverage Error: 0.5474952010740837\n----------------------------------------\nEpoch: 23\nElapsed Time: 4.11 minutes\nError: 16424.85575979948\nAverage Error: 0.547495191993316\n----------------------------------------\nEpoch: 24\nElapsed Time: 4.13 minutes\nError: 16424.85583680868\nAverage Error: 0.5474951945602894\n----------------------------------------\nEpoch: 25\nElapsed Time: 4.10 minutes\nError: 16424.855867415667\nAverage Error: 0.5474951955805222\n----------------------------------------\nEpoch: 26\nElapsed Time: 4.07 minutes\nError: 16424.85538497567\nAverage Error: 0.547495179499189\n----------------------------------------\nEpoch: 27\nElapsed Time: 4.08 minutes\nError: 16424.85559183359\nAverage Error: 0.547495186394453\n----------------------------------------\nEpoch: 28\nElapsed Time: 4.11 minutes\nError: 16424.855063438416\nAverage Error: 0.5474951687812806\n----------------------------------------\nEpoch: 29\nElapsed Time: 4.13 minutes\nError: 16424.854905873537\nAverage Error: 0.5474951635291179\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"tp, tn, fp, fn = 0, 0, 0, 0\n\nfor input_data, label in train_loader:\n    if device:\n        input_data = input_data.to(device)\n        label = label.to(device)\n                \n    output = red(input_data)\n    output = torch.argmax(output, dim=1)\n\n    if label.item() == 1:\n        if output.item() == 1:\n            tp += 1\n        else:\n            fn += 1\n    else:\n        if output.item() == 1:\n            fp += 1\n        else:\n            tn += 1\n\nprint(tp, tn, fp, fn)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T16:39:31.954277Z","iopub.execute_input":"2023-05-30T16:39:31.954666Z","iopub.status.idle":"2023-05-30T16:41:31.859440Z","shell.execute_reply.started":"2023-05-30T16:39:31.954632Z","shell.execute_reply":"2023-05-30T16:41:31.858164Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"0 22973 0 7027\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
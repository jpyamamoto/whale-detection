{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Detección Sonora de Ballenas Francas\n\n> Juan Pablo Yamamoto Zazueta  \n> [jpyamamoto@ciencias.unam.mx](mailto:jpyamamoto.ciencias.unam.mx)","metadata":{"tags":[]}},{"cell_type":"markdown","source":"## Instalación e inicialización de entorno","metadata":{"tags":[]}},{"cell_type":"markdown","source":"### Instalación de Dependencias","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"!pip install opendatasets","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:29:18.841336Z","iopub.execute_input":"2023-05-30T14:29:18.841807Z","iopub.status.idle":"2023-05-30T14:29:32.215146Z","shell.execute_reply.started":"2023-05-30T14:29:18.841765Z","shell.execute_reply":"2023-05-30T14:29:32.213798Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting opendatasets\n  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from opendatasets) (4.64.1)\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (from opendatasets) (1.5.13)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from opendatasets) (8.1.3)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (1.16.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (2023.5.7)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (2.8.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (2.28.2)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (8.0.1)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (1.26.15)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->opendatasets) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->opendatasets) (3.4)\nInstalling collected packages: opendatasets\nSuccessfully installed opendatasets-0.1.22\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install librosa","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:29:32.218883Z","iopub.execute_input":"2023-05-30T14:29:32.219204Z","iopub.status.idle":"2023-05-30T14:29:43.202959Z","shell.execute_reply.started":"2023-05-30T14:29:32.219176Z","shell.execute_reply":"2023-05-30T14:29:43.201848Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (0.10.0.post2)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa) (3.0.0)\nRequirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.23.5)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.10.1)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.2.0)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (5.1.1)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.56.4)\nRequirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.12.1)\nRequirement already satisfied: pooch<1.7,>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.6.0)\nRequirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.3.5)\nRequirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (4.5.0)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.2)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.0.5)\nRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.39.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (59.8.0)\nRequirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pooch<1.7,>=1.0->librosa) (21.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch<1.7,>=1.0->librosa) (2.28.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pooch<1.7,>=1.0->librosa) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2023.5.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install scipy","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:29:43.204401Z","iopub.execute_input":"2023-05-30T14:29:43.204806Z","iopub.status.idle":"2023-05-30T14:29:54.086782Z","shell.execute_reply.started":"2023-05-30T14:29:43.204767Z","shell.execute_reply":"2023-05-30T14:29:54.085408Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (1.10.1)\nRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scipy) (1.23.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch torchvision","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:29:54.089402Z","iopub.execute_input":"2023-05-30T14:29:54.089775Z","iopub.status.idle":"2023-05-30T14:30:05.421784Z","shell.execute_reply.started":"2023-05-30T14:29:54.089738Z","shell.execute_reply":"2023-05-30T14:30:05.420588Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.28.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"### Importar Dependencias","metadata":{"tags":[]}},{"cell_type":"code","source":"# Visualización\n\nfrom IPython.display import Audio, display, HTML, IFrame, clear_output\nfrom ipywidgets import interact, widgets\nfrom matplotlib import pyplot as plt","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-05-30T14:30:05.424403Z","iopub.execute_input":"2023-05-30T14:30:05.424781Z","iopub.status.idle":"2023-05-30T14:30:05.513701Z","shell.execute_reply.started":"2023-05-30T14:30:05.424747Z","shell.execute_reply":"2023-05-30T14:30:05.512844Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Utilidades\n\nimport glob\nimport numpy as np\nimport os\nimport csv\nimport time","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:30:14.692228Z","iopub.execute_input":"2023-05-30T14:30:14.692778Z","iopub.status.idle":"2023-05-30T14:30:14.697732Z","shell.execute_reply.started":"2023-05-30T14:30:14.692744Z","shell.execute_reply":"2023-05-30T14:30:14.696509Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Herramientas\n\nimport opendatasets as od\nimport librosa\nfrom scipy.fft import fft\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:30:15.140266Z","iopub.execute_input":"2023-05-30T14:30:15.140939Z","iopub.status.idle":"2023-05-30T14:30:15.501673Z","shell.execute_reply.started":"2023-05-30T14:30:15.140905Z","shell.execute_reply":"2023-05-30T14:30:15.500780Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Red Neuronal\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom torchvision.ops.focal_loss import sigmoid_focal_loss","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-05-30T14:30:15.788341Z","iopub.execute_input":"2023-05-30T14:30:15.789448Z","iopub.status.idle":"2023-05-30T14:30:19.074209Z","shell.execute_reply.started":"2023-05-30T14:30:15.789408Z","shell.execute_reply":"2023-05-30T14:30:19.073240Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Preparación de los datos\n\nEl conjunto de datos fue desarrollado por André Karpištšenko, Eric Spaulding y Will Cukierski, a través de Kaggle en la competencia [\"The Marinexplore and Cornell University Whale Detection Challenge\"](https://kaggle.com/competitions/whale-detection-challenge).\n\nPodemos descargarlo desde Kaggle utilizando la biblioteca `opendatasets`.","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"**Nota:** Primero dirígete al sitio web de la competencia ([https://www.kaggle.com/competitions/whale-detection-challenge/data](https://www.kaggle.com/competitions/whale-detection-challenge/data)) y acepta el aviso de Copyright para poder descargar el conjunto de datos.\n\nPosteriormente, descarga tus credenciales para usar la API de Kaggle en la configuración de tu perfil, y coloca el archivo `kaggle.json` en el mismo directorio de este archivo (para ser detectado automáticamente) o copia y pega el contenido del archivo en la entrada que se desplegará al ejecutar la siguiente celda.","metadata":{}},{"cell_type":"code","source":"od.download(\"https://www.kaggle.com/competitions/whale-detection-challenge/data\")","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Procedemos a organizar los archivos en que recibimos los datos, de manera que sean fácil de explorar.\n\nLa primera celda mueve los datos de ejemplo a la carpeta `sample`, y la segunda celda pone los archivos para entrenamiento y pruebas en la carpeta `data`.","metadata":{}},{"cell_type":"code","source":"%%capture\n# Capturamos la salida porque son demasiados archivos y ocupan mucho espacio en el notebook\n\n!unzip whale-detection-challenge/small_data_sample_revised.zip -d sample/\n!cp whale-detection-challenge/sample_submission.csv sample/\n!rm -r sample/__MACOSX\n!mv sample/small_data_sample/* sample/\n!rm -r sample/small_data_sample/","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n# Capturamos la salida porque son demasiados archivos y ocupan mucho espacio en el notebook\n\n!unzip whale-detection-challenge/whale_data.zip -d .","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"archivos_entrenamiento = glob.glob('./data/train/*.aiff')\narchivos_prueba = glob.glob('./data/test/*.aiff')\n\nprint(\"Archivos de entrenamiento: {}\".format(len(archivos_entrenamiento)))\nprint(\"Archivos de test: {}\".format(len(archivos_prueba)))","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Para manipular los archivos de audio que se encuentran en formato `.aiff`, vamos a utilizar la biblioteca [librosa](https://librosa.org/) que incluye varias herramientas relacionadas al procesamiento de audio.\n\nPodemos explorar algunos ejemplos de las grabaciones que tiene el conjunto con los archivos contenidos en el directorio `sample`:","metadata":{}},{"cell_type":"code","source":"archivos_no_whale = glob.glob('./sample/no_right_whale/*.aiff')\nsamples_no_whale = [librosa.load(file, sr=None) for file in archivos_no_whale]\n\narchivos_whale = glob.glob('./sample/right_whale/*.aiff')\nsamples_whale = [librosa.load(file, sr=None) for file in archivos_whale]","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"no_whale, samplerate_nw = librosa.load('./sample/no_right_whale/train1.aiff')\nwhale, samplerate_w = librosa.load('./sample/right_whale/train9.aiff')\n\nprint(\"No whale:\")\ndisplay(Audio(no_whale, rate=samplerate_nw))\nprint(\"Whale:\")\ndisplay(Audio(whale, rate=samplerate_w))","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Todos los audios cumplen con las siguientes especificaciones:\n\n- Duración: 2 segundos\n- Frecuencia de muestreo: 2 kHz\n\nDebemos tener cuidado al utilizar la biblioteca `librosa`, pues por defecto va a hacer un resampling.","metadata":{}},{"cell_type":"code","source":"_, samplerate_original = samples_no_whale[0]\n_, samplerate_default = librosa.load('./sample/no_right_whale/train1.aiff')\n\nprint(\"Frecuencia de muestreo original: {} Hz\".format(samplerate_original))\nprint(\"Frecuencia de muestreo por defecto: {} Hz\".format(samplerate_default))","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Análisis de los datos","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"Primero que nada, para poder procesar datos de audio tenemos que entender la forma en que se representa el audio digitalmente.\n\nLo que un micrófono haría es medir la presión relativa que ejerce el medio (normalmente aire, pero en nuestro caso el medio sería agua) sobre el dispositivo de captura. De manera tal que una mayor presión representa una onda enviada a través del medio con mayor fuerza.\n\nPor otro lado, esta presión al ser en realidad la medición de ondas, tiene otra propiedad: la frecuencia. Cuando vemos la representación de una onda, según la cercanía de dos crestas de la onda es la frecuencia del sonido que escuchamos.\n\nSi bien esta presión en el mundo real se considera una función continua, para trabajar con ella digitalmente, tenemos que discretizarla. Para esto se toman muestras en intervalos de tiempo bien definidos, y se redondean a un valor representable según la precisión con que cuenta la computadora.\n\nEsta es, a grandes rasgos, la manera en que se almacena audio de forma digital. Esto nos lleva a la primera visualización que podemos hacer de los datos que tenemos, y es la visualización por amplitud de onda:","metadata":{"tags":[]}},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 9))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Amplitud de Onda: Sin Ballenas')\n\nfor ax, sample in zip(plots, samples_no_whale):\n    audio = sample[0]\n    ax.plot(audio)\n    ax.set_xlim([0, audio.shape[0]])\n    ax.set_ylim([-0.1, 0.1])\n    ax.set_xlabel('Muestra')\n    ax.set_ylabel('Amplitud')\n    \nax6.axis('off');","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 9))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Amplitud de Onda: Con Ballenas')\n\nfor ax, sample in zip(plots, samples_whale):\n    audio = sample[0]\n    ax.plot(audio)\n    ax.set_xlim([0, audio.shape[0]])\n    ax.set_ylim([-0.1, 0.1])\n    ax.set_xlabel('Muestra')\n    ax.set_ylabel('Amplitud')\n    \nax6.axis('off');","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como mencionamos anteriormente, la frecuencia de un sonido depende de la cercanía entre dos crestas de la onda medida. Por otro lado, al discretizar la onda, únicamente podemos tomar medidas cada cierto intervalo de tiempo. Esto quiere decir que ciertas frecuencias requieren mayor cantidad de mediciones para ser capturadas apropiadamente, y otras requieren menos.\n\nLa medida de cuántas muestras debemos tomar para poder recuperar de manera apropiada la frecuencia grabada en un audio, es la [frecuencia Nyquist](https://mathworld.wolfram.com/NyquistFrequency.html), la cuál indica lo siguiente:\n\nLa mayor frecuencia $f_{\\text{Nyquist}}$ que puede ser capturada con una tasa de muestreo $v$, es $f(v)=\\dfrac{1}{2}v$.\n\nEso nos da una primera pista sobre nuestros datos: si la frecuencia de muestreo es de 2 kHz, eso quiere decir que la máxima frecuencia registrada en el sonido puede ser de 1 kHz.","metadata":{}},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 9))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Densidad Espectral: Sin Ballenas')\n\nfor ax, sample in zip(plots, samples_no_whale):\n    audio, sr = sample\n    X = fft(audio)\n    f = np.linspace(0, sr, len(X))\n    ax.plot(f, X)\n    ax.set_xlim([0, f.shape[0]/2])\n    ax.set_xlabel('Frecuencia (Hz)')\n    ax.set_ylabel('Magnitud')\n    \nax6.axis('off');","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 9))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Densidad Espectral: Con Ballenas')\n\nfor ax, sample in zip(plots, samples_whale):\n    audio, sr = sample\n    X = fft(audio)\n    f = np.linspace(0, sr, len(X))\n    ax.plot(f, X)\n    ax.set_xlim([0, f.shape[0]/2])\n    ax.set_xlabel('Frecuencia (Hz)')\n    ax.set_ylabel('Magnitud')\n    \nax6.axis('off');","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos ver en los ejemplos que efectivamente, las frecuencias capturadas se encuentran entre 0 y 1000 Hz. Tenemos valores hasta 2 kHz por la forma en que funciona la transformada de Fourier, que refleja los resultados sobre la frecuencia de Nyquist (en nuestro caso, recordemos que era 1000).\n\nSin embargo, esto sigue sin darnos suficiente información para detectar el sonido de las ballenas. Notemos que las gráficas son bastante parecidas en ambas categorías, a excepción de algunos casos donde las grabaciones con ballenas parecen tener magnitudes más grandes.\n\nSin embargo, no podemos confiar en esto, pues no sabemos si esas frecuencias son causadas por las ballenas o por cualquier otro factor en la grabación.","metadata":{}},{"cell_type":"markdown","source":"## Conociendo a las Ballenas","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"Investigando más sobre las ballenas francas y los sonidos que hacen, encontramos los siguientes datos relevantes:\n\n- Producen 3 tipos de sonidos: gemidos, quejidos y eruptos.\n- La mayoría de los sonidos que producen se mantienen por debajo de los 500 Hz.\n- Pocas veces emiten sonidos que alcanzan hasta los 4 kHz.\n- El sonido distintivo de las ballenas francas es el \"whoop\" o \"up call\":\n    - Sube de los 50 Hz a los 440 Hz.\n    - Dura alrededor de 2 segundos.\n    - Se utiliza para llamar a otras ballenas francas y generalmente las atrae a reunirse.\n    - Es un sonido que emiten de manera constante y común.\n    - Es el sonido más comúnmente utilizado por los expertos para identificar ballenas francas.\n    \nDe los datos anteriores, considero que la mejor vía para detectar a las ballenas es usando el sonido \"whoop\", confiando en lo que hacen los expertos. Esto nos ayuda a identificar qué tipo de patrones buscar:\n- Incremento en la frecuencia.\n- Comienza cerca de 50 Hz y sube cerca de 440 Hz.\n- Presente en la duración de la grabación.","metadata":{}},{"cell_type":"markdown","source":"A continuación podemos ver una grabación donde se escucha el sonido \"whoop\". Una grabación más clara de este sonido se escucha en el siguiente video que no podemos incrustar en el notebook por restricciones impuestas por la plataforma donde se publicó: [North Atlantic Right Whale \"up call\"](https://vimeo.com/227009627).","metadata":{}},{"cell_type":"code","source":"IFrame(src=\"https://www.youtube.com/embed/1WFnX4zO9GU\", height=315, width=560)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos ver en los videos que se están usando espectrogramas para visualizar las frecuencias del sonido, y en ambos vemos unas curvas convexas.\n\nEsto concuerda con la imagen provista en la página del concurso, distinguiendo el sonido de la ballena franca:\n\n![Imagen Espectrograma](https://storage.googleapis.com/kaggle-competitions/kaggle/3353/media/whale_detection_challenge-cwc-es.png)","metadata":{}},{"cell_type":"markdown","source":"Si bien la visualización de amplitud de onda nos puede dar una idea de qué frecuencias colaboran a la onda durante los 2 segundos de grabación, no es suficiente conocer que hay sonidos en las frecuencias 50 - 440 kHz. También necesitamos saber que siguen el patrón ascendente. De otra manera podría ser que hay otros factores generando sonidos en esas frecuencias, sin estar relacionados.\n\nPor lo tanto, tenemos que visualizar las frecuencias no sólo por su contribución a la onda total, sino considerando también su magnitud en el tiempo. Para ello vamos a utilizar los **espectrogramas**.","metadata":{}},{"cell_type":"markdown","source":"## Espectrogramas","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"Para visualizar las frecuencias que componen una onda a través del dominio del tiempo, podemos usar espectrogramas. Estos van a descomponer la onda en sus frecuencias, en una cierta ventana de tiempo. Luego, va a utilizar códigos de color para mostrar la intensidad en decibelios de una cierta frecuencia en cada intervalo.\n\nPodemos visualizarlo de la siguiente manera:","metadata":{}},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 15))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Frecuencias: Sin Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_no_whale):\n    audio, sr = sample\n    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n    img = librosa.display.specshow(D, y_axis='linear', x_axis='time', sr=sr, ax=ax)\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 15))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Frecuencias: Con Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_whale):\n    audio, sr = sample\n    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n    img = librosa.display.specshow(D, y_axis='linear', x_axis='time', sr=sr, ax=ax)\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como podemos ver, los espectrogramas contienen demasiada información en un comienzo, y no son precisamente informativos. Vamos a intentar limpiar un poco más los datos para ser capaces de extraer la información relevante a nuestro problema.\n\nUna primera mejora que podemos intentar aplicar es únicamente considerar las frecuencias en el rango 0 Hz - 500 Hz. Esto es porque, como vimos antes, es el rango de frecuencias que emiten las ballenas.","metadata":{}},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Frecuencias: Sin Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_no_whale):\n    audio, sr = sample\n    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n    img = librosa.display.specshow(D, y_axis='linear', x_axis='time', sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Frecuencias: Con Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_whale):\n    audio, sr = sample\n    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n    img = librosa.display.specshow(D, y_axis='linear', x_axis='time', sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ahora estamos limitando los espectrogramas a frecuencias hasta los 500 Hz. Igualmente notemos que los intervalos de tiempo son demasiado amplios. Si contamos las divisiones verticales, encontramos que solo hay 8 ventanas de tiempo en las que estamos midiendo las frecuencias.\n\nEl algoritmo que utilizamos (Short Time Fourier Transform) requiere que indiquemos los siguientes parámetros:\n- Tamaño del intervalo: La cantidad de muestras que se van a considerar en la ventana a la que se aplica la transformada de Fourier.\n- Tamaño del salto: La cantidad de muestras a desplazarnos entre una ventana de tiempo y la siguiente.\n\nEn realidad no hay una medida concreta sobre qué valores deben tomar esas variables. Mediante prueba y error (podemos hacer la prueba en la siguiente celda) encontramos valores que nos convencieron pues parecen entregar imágenes descriptivas, sin ser de un tamaño no manejable.\n","metadata":{}},{"cell_type":"code","source":"@interact(\n    frame_size = widgets.IntSlider(min=10, max=500, step=1, value=256),\n)\ndef visualize_stft(frame_size):\n    fig, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(12, 4))\n    \n    hop_length = frame_size // 4\n\n    fig.suptitle('Espectrograma (Intervalo: {}, Salto: {})'.format(frame_size, hop_length))\n\n    audio_nw, sr_nw = samples_no_whale[4]\n    audio_w, sr_w = samples_whale[4]\n    \n    D_nw = librosa.amplitude_to_db(np.abs(librosa.stft(audio_nw, hop_length=hop_length, n_fft=frame_size)), ref=np.max)\n    img = librosa.display.specshow(D_nw, y_axis='linear', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr_nw, ax=ax1)\n    \n    D_w = librosa.amplitude_to_db(np.abs(librosa.stft(audio_w, hop_length=hop_length, n_fft=frame_size)), ref=np.max)\n    img = librosa.display.specshow(D_w, y_axis='linear', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr_w, ax=ax2)\n    \n    ax1.set_ylim([0, 500])\n    ax1.set_xlabel('Tiempo (segundos)')\n    ax1.set_ylabel('Frecuencia')\n    ax1.set_title('Sin Ballena')\n    \n    ax2.set_ylim([0, 500])\n    ax2.set_xlabel('Tiempo (segundos)')\n    ax2.set_ylabel('Frecuencia')\n    ax2.set_title('Con Ballena')\n    \n    fig.subplots_adjust(right=0.8)\n    cbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\n    fig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Algunos consejos para seleccionar esos valores, que encontramos son los siguientes:\n- Que el tamaño del intervalo sea una potencia de 2.\n- Que el tamaño del salto sea una cuarta parte del tamaño del intervalo.\n\nPor ello, habiendo encontrado valores que nos convencieron en la celda anterior, redondeamos el tamaño del intervalo a la potencia de 2 más cercana y dimos el tamaño del salto una cuarta parte de este.\n\nEsto nos dio los siguientes valores:","metadata":{}},{"cell_type":"code","source":"frame_size = 256\nhop_length = frame_size // 4\n\nprint(\"Tamaño del intervalo: {}\".format(frame_size))\nprint(\"Tamaño del salto: {}\".format(hop_length))","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Frecuencias: Sin Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_no_whale):\n    audio, sr = sample\n    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio, hop_length=hop_length, n_fft=frame_size)), ref=np.max)\n    img = librosa.display.specshow(D, y_axis='linear', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Frecuencias: Con Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_whale):\n    audio, sr = sample\n    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio, hop_length=hop_length, n_fft=frame_size)), ref=np.max)\n    img = librosa.display.specshow(D, y_axis='linear', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Espectrogramas de Mel","metadata":{}},{"cell_type":"markdown","source":"Hay un último hecho que queremos tomar en cuenta al momento de generar los espectrogramas. Esto es que los humanos (y en general los animales) no percibimos el sonido de forma lineal. Es decir, al reproducir dos frecuencias a un intervalo dado y luego reproducir dos notas al mismo intervalo en una frecuencia distinta (y asumamos que lejana), percibiremos claramente que un par suena más parecido que el otro.\n\nEsto se debe a que el sonido se percibe de forma logarítmica. Mientras mayor es la frecuencia, más lejanas deben estar dos frecuencias para que el intervalo entre ellas se **perciba** como constante.\n\nPuesto que esto es algo generalizado en los animales, podemos asumir que las ballenas también perciben de esta manera el sonido. Y por lo mismo parece apropiado asumir que la forma de analizar el sonido emitido por ellas debe ajustarse a esta métrica.\n\nPara ello vamos a utilizar los espectrogramas de Mel.\n\nEn la imagen siguiente podemos visualizar cómo funciona el filtro que será aplicado a la imagen. Podemos ver que según la frecuencia del sonido, será la intensidad del filtro que se aplique.\n\nLa tasa de muestreo al ser baja (recordemos que era de 200), no permite visualizar tan claramente la forma logarítmica que tiene este filtro, debido a que son pocas las frecuencias alcanzables. Pero podemos hacer el experimento de incrementar la variable `sr` a un valor como `22050` (la tasa de muestreo estándar para archivos de música) y va a ser clara la diferencia.","metadata":{}},{"cell_type":"code","source":"@interact(\n    mel_bands = widgets.IntSlider(min=5, max=50, step=1, value=10),\n)\ndef visualize_stft(mel_bands):\n    fig, ax = plt.subplots()\n    sr = 200\n    filter_banks = librosa.filters.mel(n_fft=frame_size, sr=sr, n_mels=mel_bands)\n    librosa.display.specshow(filter_banks, sr=sr, x_axis='linear')\n    fig.colorbar(img, ax=ax, format='%+2.0f dB')\n    ax.set(title='Espectrograma de los filtros de Mel')","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vamos a buscar el número apropiado de bandas de Mel para nuestro caso de uso. No encontré alguna fórmula o heurística para determinar este valor, sino que más bien la elección debe ir guiada por la resolución que da (y lo que esperamos ver en la imagen).\n\nEn la siguiente celda podemos experimentar con el valor que consideramos da un buen resultado.","metadata":{}},{"cell_type":"code","source":"@interact(\n    mel_bands = widgets.IntSlider(min=10, max=200, step=1, value=128),\n)\ndef visualize_stft(mel_bands):\n    fig, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(12, 4))\n    \n    fig.suptitle('Espectrograma (Bandas de Mel: {})'.format(mel_bands))\n\n    audio_nw, sr_nw = samples_no_whale[4]\n    audio_w, sr_w = samples_whale[4]\n    \n    mel_spec_nw = librosa.feature.melspectrogram(y=audio_nw, sr=sr_nw, n_fft=frame_size, hop_length=hop_length, n_mels=mel_bands)\n    mel_spec_w = librosa.feature.melspectrogram(y=audio_w, sr=sr_w, n_fft=frame_size, hop_length=hop_length, n_mels=mel_bands)\n    \n    D_nw = librosa.power_to_db(mel_spec_nw, ref=np.max)\n    img = librosa.display.specshow(D_nw, y_axis='mel', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr_nw, ax=ax1)\n    \n    D_w = librosa.power_to_db(mel_spec_w, ref=np.max)\n    img = librosa.display.specshow(D_w, y_axis='mel', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr_w, ax=ax2)\n    \n    ax1.set_ylim([0, 500])\n    ax1.set_xlabel('Tiempo (segundos)')\n    ax1.set_ylabel('Frecuencia')\n    ax1.set_title('Sin Ballena')\n    \n    ax2.set_ylim([0, 500])\n    ax2.set_xlabel('Tiempo (segundos)')\n    ax2.set_ylabel('Frecuencia')\n    ax2.set_title('Con Ballena')\n    \n    fig.subplots_adjust(right=0.8)\n    cbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\n    fig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El valor que nos convenció fue el de la siguiente celda.\n\n- Con valores más grandes, parece haber mucho ruido en la imagen.\n- Con valores más pequeños se desvanecen algunos colores y perdemos información.","metadata":{}},{"cell_type":"code","source":"mel_bands = 128\n\nprint(\"Bandas de Mel: {}\".format(mel_bands))","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Mel: Sin Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_no_whale):\n    audio, sr = sample\n    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=frame_size, hop_length=hop_length, n_mels=mel_bands)\n    D = librosa.power_to_db(mel_spec, ref=np.max)\n    img = librosa.display.specshow(D, y_axis='mel', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Mel: Con Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_whale):\n    audio, sr = sample\n    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=frame_size, hop_length=hop_length, n_mels=mel_bands)\n    D = librosa.power_to_db(mel_spec, ref=np.max)\n    img = librosa.display.specshow(D, y_axis='mel', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finalmente, notemos que la forma en que utilizamos la escala de colores es lineal. Si bien para un humano es más fácil visualizar la intensidad por colores, la computadora lo va a leer como números de mayor o menor tamaño.\n\nPor lo tanto, podemos convertir la imagen a escala de grises para facilitar su procesamiento por la red neuronal.","metadata":{}},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Mel: Sin Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_no_whale):\n    audio, sr = sample\n    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=frame_size, hop_length=hop_length, n_mels=mel_bands)\n    D = librosa.power_to_db(mel_spec, ref=np.max)\n    img = librosa.display.specshow(D, cmap='gray', y_axis='mel', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\nplots = [ax1, ax2, ax3, ax4, ax5]\n\nfig.suptitle('Espectrograma de Mel: Con Ballenas')\nimg = None\n\nfor ax, sample in zip(plots, samples_whale):\n    audio, sr = sample\n    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=frame_size, hop_length=hop_length, n_mels=mel_bands)\n    D = librosa.power_to_db(mel_spec, ref=np.max)\n    img = librosa.display.specshow(D, cmap='gray', y_axis='mel', x_axis='time', hop_length=hop_length, n_fft=frame_size, sr=sr, ax=ax)\n    ax.set_ylim([0, 500])\n    ax.set_xlabel('Tiempo (segundos)')\n    ax.set_ylabel('Frecuencia')\n    \nax6.axis('off')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.10, 0.02, 0.8])\nfig.colorbar(img, cax=cbar_ax, format=\"%+2.f dB\");","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Procesamiento de las imágenes","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Tras haber determinado la forma en que convertiremos los archivos de audio a imágenes, y encontrando la configuración adecuada, vamos a procesar los archivos para poder utilizarlos con la red neuronal.","metadata":{}},{"cell_type":"code","source":"def audio_to_img(audio, sr):\n    img = librosa.feature.melspectrogram(y=audio,\n                                         sr=sr,\n                                         n_fft=frame_size,\n                                         hop_length=hop_length,\n                                         n_mels=mel_bands)\n   \n    img = librosa.power_to_db(img, ref=np.max)\n    img = np.flip(img, axis=0)\n    img = np.c_[ img[64:], np.ones(64)] # Imagen cuadrada\n    \n    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n    img = img * 255\n    \n    img = img.astype(np.uint8)\n    img = Image.fromarray(img)\n\n    return img\n\ndef convert_audio_file(file, output):\n    audio, sr = librosa.load(file, sr=None)\n    img = audio_to_img(audio, sr)\n    img.save(output, format='PNG', optimize=False, compress_level=0)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_labels = dict()\n\nwith open('./data/train.csv', 'r') as data:\n    next(data)\n    \n    for row in csv.reader(data, delimiter=','):\n        training_labels[row[0]] = int(row[1])","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Primero convertimos los archivos de audio para entrenamiento a imágenes `png` sin compresión ni perdida. Los colocaremos en los directorios:\n- `./data_img/train/negative`: Si tiene etiqueta negativa (no hay ballena presente).\n- `./data_img/train/positive`: Si tiene etiqueta positiva (sí hay ballena presente).","metadata":{}},{"cell_type":"code","source":"!mkdir -p data_img/train/negative\n!mkdir -p data_img/train/positive","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = './data_img/train/'\n\nsubpath = ['negative/', 'positive/']\n\ni = 1\ntotal = len(archivos_entrenamiento)\n\nfor file in archivos_entrenamiento:\n    filename = os.path.basename(file)\n    file_noext = os.path.splitext(filename)[0]\n    \n    label = training_labels[filename]\n    output_filename = base_path + subpath[label] + file_noext + '.png'\n    \n    clear_output(wait=True)\n    print('Convirtiendo archivo {} a {}\\nArchivo {}/{}'.format(filename, file_noext + '.png', i, total))\n    \n    convert_audio_file(file, output_filename)\n    i += 1\n    \nprint(\"Completado.\")","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"También convertimos los archivos de audio del conjunto de prueba.\n\nEstarán en el directorio `./data_img/test/`.","metadata":{}},{"cell_type":"code","source":"!mkdir -p data_img/test/","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = './data_img/test/'\n\ni = 1\ntotal = len(archivos_prueba)\n\nfor file in archivos_prueba:\n    filename = os.path.basename(file)\n    file_noext = os.path.splitext(filename)[0]\n    \n    output_filename = base_path + file_noext + '.png'\n    \n    clear_output(wait=True)\n    print('Convirtiendo archivo {} a {}\\nArchivo {}/{}'.format(filename, file_noext + '.png', i, total))\n    \n    convert_audio_file(file, output_filename)\n    i += 1\n    \nprint(\"Completado.\")","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Habiendo convertido todas las imágenes, tenemos los siguientes conjuntos de datos.","metadata":{}},{"cell_type":"code","source":"img_train_neg = glob.glob('/kaggle/input/whale/data_img/train/negative/*.png')\nimg_train_pos = glob.glob('/kaggle/input/whale/data_img/train/positive/*.png')\nimg_test = glob.glob('/kaggle/input/whale/data_img/test/*.png')\n\nprint(\"Imágenes de prueba: {}\".format(len(img_test)))\nprint(\"Imágenes de entrenamiento (categoría positiva): {}\".format(len(img_train_pos)))\nprint(\"Imágenes de entrenamiento (categoría negativa): {}\".format(len(img_train_neg)))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-05-30T14:31:55.796475Z","iopub.execute_input":"2023-05-30T14:31:55.796868Z","iopub.status.idle":"2023-05-30T14:31:57.004651Z","shell.execute_reply.started":"2023-05-30T14:31:55.796839Z","shell.execute_reply":"2023-05-30T14:31:57.003711Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Imágenes de prueba: 54503\nImágenes de entrenamiento (categoría positiva): 7027\nImágenes de entrenamiento (categoría negativa): 22973\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### DataSets y DataLoaders","metadata":{}},{"cell_type":"markdown","source":"Vamos a crear una clase para un Dataset que tome los datos de las imágenes de ballenas y las clasifique con su etiqueta correspondiente.","metadata":{}},{"cell_type":"code","source":"class WhaleSpectrogramsDataset(Dataset):\n    def __init__(self, positive_paths, negative_paths, transform=None, target_transform=None):\n        self.imgs = list(map(lambda p: (1, p), positive_paths)) + list(map(lambda p: (0, p), negative_paths))\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.imgs)\n\n    def __getitem__(self, idx):\n        label, img_path = self.imgs[idx]\n        image = Image.open(img_path)\n        \n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n            \n        return image, label","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-05-30T14:32:01.981082Z","iopub.execute_input":"2023-05-30T14:32:01.981479Z","iopub.status.idle":"2023-05-30T14:32:01.992475Z","shell.execute_reply.started":"2023-05-30T14:32:01.981447Z","shell.execute_reply":"2023-05-30T14:32:01.991251Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Con lo anterior, podemos crear nuestros conjuntos de datos.\n\nPara el dataset de prueba, vamos a ignorar las etiquetas entonces las tomamos como clasificadas indistintamente.","metadata":{}},{"cell_type":"code","source":"train_dataset = WhaleSpectrogramsDataset(positive_paths=img_train_pos,\n                                         negative_paths=img_train_neg,\n                                         transform=transforms.Compose([\n                                             transforms.Resize((227,227)),\n                                             transforms.ToTensor(),\n                                             transforms.Normalize([0.5], [0.5])\n                                         ]),\n                                         target_transform=torch.tensor)\n\nmid = len(img_test) // 2\ntest_dataset = WhaleSpectrogramsDataset(positive_paths=img_test[:mid],\n                                        negative_paths=img_test[mid:],\n                                        transform=transforms.Compose([\n                                            transforms.Resize((227,227)),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize([0.5], [0.5])\n                                        ]),\n                                        target_transform=torch.tensor)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-05-30T14:32:03.948779Z","iopub.execute_input":"2023-05-30T14:32:03.949496Z","iopub.status.idle":"2023-05-30T14:32:03.981757Z","shell.execute_reply.started":"2023-05-30T14:32:03.949461Z","shell.execute_reply":"2023-05-30T14:32:03.980767Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Con los datasets anteriores, podemos crear un Dataloader que divida los datos en batches de cierto tamaño para el entrenamiento. Vamos a utilizar batches de tamaño 1, ","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, shuffle=True,  num_workers=2)\ntest_loader  = DataLoader(test_dataset,  shuffle=False, num_workers=2)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-05-30T14:32:06.040529Z","iopub.execute_input":"2023-05-30T14:32:06.040900Z","iopub.status.idle":"2023-05-30T14:32:06.047197Z","shell.execute_reply.started":"2023-05-30T14:32:06.040869Z","shell.execute_reply":"2023-05-30T14:32:06.045834Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Red Neuronal","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Para la red neuronal, nos estaremos basando en la arquitectura de AlexNet.\n\nEsta fue introducida por primera vez en el artículo [\"ImageNet Classification with Deep Convolutional\nNeural Networks\"](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) escrito por Alex Krizhevsky, Ilya Sutskever y Geoffrey E. Hinton. Se utilizó en la competencia ImageNet del 2012, obteniendo muy buenos resultados.\n\nPrincipalmente se utiliza para imágenes de tamaño 227x227, con 3 canales de color. Sin embargo, veremos que podemos adecuarla a nuestro caso de uso.\n\nLa arquitectura es la siguiente (imagen de [Paras Varshney](https://github.com/blurred-machine)):\n\n![Arquitectura AlexNet](https://raw.githubusercontent.com/blurred-machine/Data-Science/master/Deep%20Learning%20SOTA/img/alexnet2.png)\n\nLa imagen omite algunos detalles como lo son las capas DropOut y las activaciones ReLU, pero en la implementación tenemos cuidado de incluirlas.","metadata":{}},{"cell_type":"code","source":"class Red(nn.Module):\n    def __init__(self, num_classes):\n        super(Red, self).__init__()\n        \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2)\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2)\n        )\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n        self.conv4 = nn.Sequential(\n            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n        self.conv5 = nn.Sequential(\n            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2)\n        )\n        self.flatten = nn.Flatten(start_dim=1)\n        self.fc1 = nn.Sequential(\n            nn.Dropout(p=0.5),\n            nn.Linear(in_features=256*6*6, out_features=4096),\n            nn.ReLU()\n        )\n        self.fc2 = nn.Sequential(\n            nn.Dropout(p=0.5),\n            nn.Linear(in_features=4096, out_features=4096),\n            nn.ReLU()\n        )\n        self.fc3 = nn.Sequential(\n            nn.Linear(in_features=4096, out_features=num_classes),\n            nn.Softmax(dim=1)\n        )\n        \n    def forward(self, x, single=False):\n        if single:\n            x = x[None,:]\n        \n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        x = self.fc3(x)\n        \n        return x\n    \n    def train(self, epochs, data_loader, criterion, optimizer, device=None, debug=False, save_dir=None):\n        error = np.zeros(epochs)\n        \n        for epoch in range(epochs):\n            running_loss = 0.0\n            start_time = time.time()\n            i = 0\n            \n            for input_data, label in data_loader:\n                i += 1\n                optimizer.zero_grad()\n                \n                if device:\n                    input_data = input_data.to(device)\n                    label = label.to(device)\n                \n                output = self(input_data)\n                loss = criterion(output, label)\n                \n                loss.backward()\n                optimizer.step()\n                \n                running_loss += loss.item()\n                \n            error[epoch] = running_loss\n            end_time = time.time()\n            \n            if debug:\n                print('-'*40)\n                print('Epoch: {}\\nElapsed Time: {:0.2f} minutes\\nError: {}\\nAverage Error: {}'.format(epoch, (end_time - start_time) / 60, running_loss, running_loss / i))\n            \n            if save_dir:\n                filename = os.path.join(save_dir, 'model_{}.pt'.format(epoch))\n                torch.save(self.state_dict(), filename)\n            \n        plt.plot(error)\n        plt.xlabel('epoch')\n        plt.ylabel('error');","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:32:11.457675Z","iopub.execute_input":"2023-05-30T14:32:11.458069Z","iopub.status.idle":"2023-05-30T14:32:11.477789Z","shell.execute_reply.started":"2023-05-30T14:32:11.458040Z","shell.execute_reply":"2023-05-30T14:32:11.476670Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Para el entrenamiento, vamos a utilizar una función de pérdida llamada Focal Loss.\n\nEsta es una mejora a la entropía cruzada, que sabemos es de las mejores opciones cuando tenemos tareas de clasificación. Sin embargo, la pérdida focal va a permitir adaptarse mejor a aquellos casos que la red aún no aprende bien, en vez de poner toda su atención en los casos ya aprendidos.\n\nEsto es útil cuando el conjunto de datos de entrada no es del todo balanceado, como es nuestro caso en donde tenemos casi el triple de ejemplares de una categoría.\n\nEl optimizador a utilizar en nuestro caso será Adam. La elección se basa simplemente en que, en nuestra experiencia a lo largo del curso, este tiende a comportarse bien.","metadata":{}},{"cell_type":"code","source":"red = Red(num_classes=2)\n\ncriterion = lambda output, label: sigmoid_focal_loss(output, F.one_hot(label, num_classes=2).to(torch.float), reduction='mean')\ncriterion = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(red.parameters(), lr=0.001)\noptimizer = optim.SGD(red.parameters(), lr=0.005)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:33:50.160667Z","iopub.execute_input":"2023-05-30T14:33:50.161230Z","iopub.status.idle":"2023-05-30T14:33:50.632575Z","shell.execute_reply.started":"2023-05-30T14:33:50.161198Z","shell.execute_reply":"2023-05-30T14:33:50.631613Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Vamos a configurar CUDA cuando se encuentre disponible.","metadata":{}},{"cell_type":"code","source":"cuda = torch.cuda.is_available()\nprint(\"CUDA disponible:\", cuda)\n\nif cuda:\n    # Descomentar y cambiar el dispositivo, en caso de desearlo.\n    # torch.cuda.set_device(1)\n    \n    cuda_id = torch.cuda.current_device()\n    print(\"Dispositivo CUDA:\", torch.cuda.get_device_name(cuda_id))\n    \ndevice = torch.device('cuda' if cuda else 'cpu')\n\nred.to(device)\n\nprint(\"Utilizando:\", device)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-05-30T14:33:51.991985Z","iopub.execute_input":"2023-05-30T14:33:51.992382Z","iopub.status.idle":"2023-05-30T14:33:52.067491Z","shell.execute_reply.started":"2023-05-30T14:33:51.992324Z","shell.execute_reply":"2023-05-30T14:33:52.066378Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"CUDA disponible: True\nDispositivo CUDA: Tesla P100-PCIE-16GB\nUtilizando: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"red.train(epochs=30, data_loader=train_loader, criterion=criterion, optimizer=optimizer, device=device, debug=True, save_dir='/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2023-05-30T14:33:53.600511Z","iopub.execute_input":"2023-05-30T14:33:53.600874Z","iopub.status.idle":"2023-05-30T16:37:31.227867Z","shell.execute_reply.started":"2023-05-30T14:33:53.600838Z","shell.execute_reply":"2023-05-30T16:37:31.226852Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"----------------------------------------\nEpoch: 0\nElapsed Time: 3.87 minutes\nError: 16492.117018669844\nAverage Error: 0.5497372339556614\n----------------------------------------\nEpoch: 1\nElapsed Time: 4.02 minutes\nError: 16424.972415864468\nAverage Error: 0.5474990805288156\n----------------------------------------\nEpoch: 2\nElapsed Time: 4.01 minutes\nError: 16424.909214287996\nAverage Error: 0.5474969738095998\n----------------------------------------\nEpoch: 3\nElapsed Time: 4.05 minutes\nError: 16424.888523072004\nAverage Error: 0.5474962841024001\n----------------------------------------\nEpoch: 4\nElapsed Time: 4.34 minutes\nError: 16424.87847533822\nAverage Error: 0.5474959491779406\n----------------------------------------\nEpoch: 5\nElapsed Time: 4.49 minutes\nError: 16424.872795671225\nAverage Error: 0.5474957598557075\n----------------------------------------\nEpoch: 6\nElapsed Time: 4.14 minutes\nError: 16424.86837208271\nAverage Error: 0.547495612402757\n----------------------------------------\nEpoch: 7\nElapsed Time: 4.14 minutes\nError: 16424.866963922977\nAverage Error: 0.5474955654640993\n----------------------------------------\nEpoch: 8\nElapsed Time: 4.13 minutes\nError: 16424.864463955164\nAverage Error: 0.5474954821318389\n----------------------------------------\nEpoch: 9\nElapsed Time: 4.08 minutes\nError: 16424.863263249397\nAverage Error: 0.5474954421083132\n----------------------------------------\nEpoch: 10\nElapsed Time: 4.08 minutes\nError: 16424.860868632793\nAverage Error: 0.5474953622877597\n----------------------------------------\nEpoch: 11\nElapsed Time: 4.07 minutes\nError: 16424.86068561673\nAverage Error: 0.5474953561872243\n----------------------------------------\nEpoch: 12\nElapsed Time: 4.07 minutes\nError: 16424.85982069373\nAverage Error: 0.5474953273564577\n----------------------------------------\nEpoch: 13\nElapsed Time: 4.06 minutes\nError: 16424.8589682281\nAverage Error: 0.5474952989409367\n----------------------------------------\nEpoch: 14\nElapsed Time: 4.08 minutes\nError: 16424.85857564211\nAverage Error: 0.547495285854737\n----------------------------------------\nEpoch: 15\nElapsed Time: 4.14 minutes\nError: 16424.858139634132\nAverage Error: 0.5474952713211377\n----------------------------------------\nEpoch: 16\nElapsed Time: 4.11 minutes\nError: 16424.857522547245\nAverage Error: 0.5474952507515748\n----------------------------------------\nEpoch: 17\nElapsed Time: 4.12 minutes\nError: 16424.857431054115\nAverage Error: 0.5474952477018038\n----------------------------------------\nEpoch: 18\nElapsed Time: 4.13 minutes\nError: 16424.857038140297\nAverage Error: 0.5474952346046765\n----------------------------------------\nEpoch: 19\nElapsed Time: 4.14 minutes\nError: 16424.85689085722\nAverage Error: 0.5474952296952407\n----------------------------------------\nEpoch: 20\nElapsed Time: 4.12 minutes\nError: 16424.85614231229\nAverage Error: 0.5474952047437429\n----------------------------------------\nEpoch: 21\nElapsed Time: 4.13 minutes\nError: 16424.85620048642\nAverage Error: 0.5474952066828808\n----------------------------------------\nEpoch: 22\nElapsed Time: 4.14 minutes\nError: 16424.85603222251\nAverage Error: 0.5474952010740837\n----------------------------------------\nEpoch: 23\nElapsed Time: 4.11 minutes\nError: 16424.85575979948\nAverage Error: 0.547495191993316\n----------------------------------------\nEpoch: 24\nElapsed Time: 4.13 minutes\nError: 16424.85583680868\nAverage Error: 0.5474951945602894\n----------------------------------------\nEpoch: 25\nElapsed Time: 4.10 minutes\nError: 16424.855867415667\nAverage Error: 0.5474951955805222\n----------------------------------------\nEpoch: 26\nElapsed Time: 4.07 minutes\nError: 16424.85538497567\nAverage Error: 0.547495179499189\n----------------------------------------\nEpoch: 27\nElapsed Time: 4.08 minutes\nError: 16424.85559183359\nAverage Error: 0.547495186394453\n----------------------------------------\nEpoch: 28\nElapsed Time: 4.11 minutes\nError: 16424.855063438416\nAverage Error: 0.5474951687812806\n----------------------------------------\nEpoch: 29\nElapsed Time: 4.13 minutes\nError: 16424.854905873537\nAverage Error: 0.5474951635291179\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAk8AAAGwCAYAAACw64E/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9qElEQVR4nO3dfVhU953//9fAwHAjjBqiQAWizXpDtWjUVZFoSBqRGMSbNtbsGm1S26ybNcWbrMYmsUmtrvebkoZeMV+T9ur1M92ltSYkFnshWlfTqBVvoquR2EKrrG20IGAGZM7vDzLHUCA6ODOHmTwf1zWROeczZz7ncHLxut7ncz7HZhiGIQAAANyUMKs7AAAAEEwITwAAAF4gPAEAAHiB8AQAAOAFwhMAAIAXCE8AAABeIDwBAAB4wW51B0KJ2+3W+fPnFRcXJ5vNZnV3AADATTAMQ1euXFFycrLCwm5cVyI8+dD58+eVkpJidTcAAEAXVFdXq1+/fjdsR3jyobi4OEmtBz8+Pt7i3gAAgJtRV1enlJQU8+/4jRCefMhzqS4+Pp7wBABAkLnZITcMGAcAAPAC4QkAAMALhCcAAAAvEJ4AAAC8QHgCAADwAuEJAADAC4QnAAAALxCeAAAAvEB4AgAA8ALhCQAAwAuEJwAAAC8QngAAALxAeAoCH9W79MePGvRxc4vVXQEA4HOP8BQEpv3ofzRxXblOXqizuisAAHzuEZ6CQGykXZLU6KLyBACA1QhPQSAmMlyS1NB0zeKeAAAAwlMQiHV8UnkiPAEAYDnCUxAwK09ctgMAwHKEpyBgjnmi8gQAgOUIT0EgmsoTAADdBuEpCDDmCQCA7sPS8LR3717l5eUpOTlZNptN27dvb9fm1KlTmjp1qpxOp+Li4jR27FhVVVW1a2cYhnJzczvczu9//3vdf//96tmzp2677TZ961vfUn19fZs2VVVVysvLU2xsrBISErRw4UI1NTX5cne7zDPmqbGJyhMAAFazNDw1NDQoIyNDhYWFHa6vrKxUVlaWBg8erPLych09elTPPPOMoqKi2rXdvHmzbDZbu+Xnz5/XV77yFd1555363e9+p507d+r999/XvHnzzDYtLS2aMmWKGhoatG/fPm3btk3FxcVavHixz/b1Vlwf80R4AgDAanYrvzw3N1e5ubmdrl+xYoUeeOABrV271lw2YMCAdu2OHj2qjRs36uDBg0pKSmqz7q233lJERIReeuklhYW1ZsWXXnpJI0aM0NmzZ3XnnXeqtLRUJ0+eVHV1tZKTkyVJGzZs0Lx587Rq1SrFx8d32D+XyyWXy2W+r6vzzwzgMQ7PmCcu2wEAYLVuO+bJ7XarpKREAwcOVE5Ojvr06aMxY8a0uyTX2Nio2bNnq7CwUImJie2243K5FBkZaQYnSYqOjpYk7du3T5J04MABDR061AxOkpSTkyOXy6XDhw932sfVq1fL6XSar5SUlFvZ5U5ReQIAoPvotuHp4sWLqq+v15o1azR58mSVlpZq+vTpmjFjhvbs2WO2KygoUGZmpvLz8zvczr333quamhqtW7dOTU1Nunz5sp5++mlJ0oULFyRJNTU16tu3b5vP9erVS5GRkaqpqem0j8uXL1dtba35qq6uvtXd7hAzjAMA0H1Yetnus7jdbklSfn6+CgoKJEnDhw/X/v37VVRUpIkTJ2rHjh0qKyvTkSNHOt3Ol770Jb3++utatGiRli9frvDwcC1cuFB9+/ZVeHi42a6j8VKGYXS43MPhcMjhcHR1F29aDM+2AwCg2+i2laeEhATZ7Xalp6e3WT5kyBDzbruysjJVVlaqZ8+estvtsttbQ8bMmTN1zz33mJ95+OGHVVNToz//+c/66KOPtHLlSv3lL39R//79JUmJiYntKkyXL19Wc3Nzu4qUFcwxT1SeAACwXLcNT5GRkRo9erROnz7dZvmZM2eUlpYmSVq2bJmOHTumiooK8yVJmzZt0tatW9tts2/fvurRo4feeOMNRUVF6f7775ckjRs3TidOnDAv40lSaWmpHA6HRo4c6ac9vHmeMU9XGfMEAIDlLL1sV19fr7Nnz5rvz507p4qKCvXu3VupqalaunSpZs2apQkTJig7O1s7d+7Um2++qfLyckmtFaOOBomnpqaaVSVJKiwsVGZmpnr06KFdu3Zp6dKlWrNmjXr27ClJmjRpktLT0zVnzhytW7dOly5d0pIlSzR//vxO77QLJMY8AQDQfVgang4dOqTs7Gzz/aJFiyRJc+fO1Wuvvabp06erqKhIq1ev1sKFCzVo0CAVFxcrKyvLq+9577339Nxzz6m+vl6DBw/Wj3/8Y82ZM8dcHx4erpKSEi1YsEDjx49XdHS0Hn74Ya1fv943O3qLPDOMf9zsVovbUHhY5+OwAACAf9kMwzCs7kSoqKurk9PpVG1trU8rVh83t2jwMzslScdXTlJcVITPtg0AwOedt3+/u+2YJ1znsIeZ1SbmegIAwFqEpyBgs9muj3tilnEAACxFeAoSPBwYAIDugfAUJDzTFVB5AgDAWoSnIOGZKLOxmcoTAABWIjwFCR7RAgBA90B4ChKxTJQJAEC3QHgKEjEOT+WJ8AQAgJUIT0HieuWJy3YAAFiJ8BQkzDFPXLYDAMBShKcgcX2STCpPAABYifAUJDwPB77KZTsAACxFeAoSMdxtBwBAt0B4ChKx5pgnKk8AAFiJ8BQkPDOM83gWAACsRXgKElSeAADoHghPQYIxTwAAdA+EpyDBs+0AAOgeCE9BwhzzROUJAABLEZ6ChGfM09WmFhmGYXFvAAD4/CI8BQlP5ema21BTi9vi3gAA8PlFeAoSMRHh5s+MewIAwDqEpyBhDw+Tw97662LcEwAA1iE8BRHP8+2Y6wkAAOsQnoKIOdcTs4wDAGAZwlMQ8YQnKk8AAFiH8BREYnhECwAAliM8BZFYh6fyxGU7AACsQngKIp7KUwNTFQAAYBnCUxCJjaTyBACA1QhPQSTGQeUJAACrEZ6CCJUnAACsR3gKItGeMU+EJwAALEN4CiJm5YnLdgAAWIbwFERieDwLAACWIzwFEU/lict2AABYh/AURJhhHAAA6xGegohnhnEeDAwAgHUIT0GEyhMAANazNDzt3btXeXl5Sk5Ols1m0/bt29u1OXXqlKZOnSqn06m4uDiNHTtWVVVV7doZhqHc3NwOt3PmzBnl5+crISFB8fHxGj9+vHbv3t2mTVVVlfLy8hQbG6uEhAQtXLhQTU1NvtzdW8az7QAAsJ6l4amhoUEZGRkqLCzscH1lZaWysrI0ePBglZeX6+jRo3rmmWcUFRXVru3mzZtls9k63M6UKVN07do1lZWV6fDhwxo+fLgefPBB1dTUSJJaWlo0ZcoUNTQ0aN++fdq2bZuKi4u1ePFi3+2sD8REMMM4AABWsxmGYVjdCUmy2Wz65S9/qWnTppnLvv71rysiIkI//elPP/OzR48e1YMPPqiDBw8qKSmpzXb++te/6vbbb9fevXt19913S5KuXLmi+Ph4/eY3v9F9992nd955Rw8++KCqq6uVnJwsSdq2bZvmzZunixcvKj4+vsPvdblccrlc5vu6ujqlpKSotra208/cir/WuzTq+7+RJH34gwcUFtZxWAQAADevrq5OTqfzpv9+d9sxT263WyUlJRo4cKBycnLUp08fjRkzpt0lucbGRs2ePVuFhYVKTExst53bbrtNQ4YM0U9+8hM1NDTo2rVr+vGPf6y+fftq5MiRkqQDBw5o6NChZnCSpJycHLlcLh0+fLjTPq5evVpOp9N8paSk+GbnOxH7yZgnSbraTPUJAAArdNvwdPHiRdXX12vNmjWaPHmySktLNX36dM2YMUN79uwx2xUUFCgzM1P5+fkdbsdms2nXrl06cuSI4uLiFBUVpU2bNmnnzp3q2bOnJKmmpkZ9+/Zt87levXopMjLSvLTXkeXLl6u2ttZ8VVdX3/qOf4aoiDB5rkwy1xMAANaw37iJNdxutyQpPz9fBQUFkqThw4dr//79Kioq0sSJE7Vjxw6VlZXpyJEjnW7HMAwtWLBAffr00W9/+1tFR0dry5YtbS7zSepwvJRhGJ2Oo5Ikh8Mhh8NxK7vpFZvNpthIu+pd11of0RIXsK8GAACf6LaVp4SEBNntdqWnp7dZPmTIEPNuu7KyMlVWVqpnz56y2+2y21uz4MyZM3XPPfeYbd566y1t27ZN48eP11133aUf/ehHio6O1uuvvy5JSkxMbFdhunz5spqbm9tVpKwWwyzjAABYqtuGp8jISI0ePVqnT59us/zMmTNKS0uTJC1btkzHjh1TRUWF+ZKkTZs2aevWrZJax0RJUlhY210NCwszq1vjxo3TiRMndOHCBXN9aWmpHA6HOS6qu4jl+XYAAFjK0st29fX1Onv2rPn+3LlzqqioUO/evZWamqqlS5dq1qxZmjBhgrKzs7Vz5069+eabKi8vl9RaMepokHhqaqr69+8vqTUY9erVS3PnztWzzz6r6OhovfLKKzp37pymTJkiSZo0aZLS09M1Z84crVu3TpcuXdKSJUs0f/58v9w1dyuiI5hlHAAAK1laeTp06JBGjBihESNGSJIWLVqkESNG6Nlnn5UkTZ8+XUVFRVq7dq2GDRumLVu2qLi4WFlZWTf9HQkJCdq5c6fq6+t17733atSoUdq3b59+9atfKSMjQ5IUHh6ukpISRUVFafz48XrooYc0bdo0rV+/3vc7fYuuT5RJ5QkAACt0m3meQoG380R0xdz/9572nPmL1n8tQ18d2c8v3wEAwOdJyMzzhI7xiBYAAKxFeAoynocD84gWAACsQXgKMrGRVJ4AALAS4SnIxDioPAEAYCXCU5Ch8gQAgLUIT0Em2jPmiakKAACwBOEpyHgqT1epPAEAYAnCU5BhzBMAANYiPAUZxjwBAGAtwlOQiWHMEwAAliI8BRlzhnEeDAwAgCUIT0GGyhMAANYiPAUZnm0HAIC1CE9BJiaitfLU3GKo6Zrb4t4AAPD5Q3gKMtGf3G0nSVe5dAcAQMARnoJMpD1MkeGtv7YGLt0BABBwhKcgFMO4JwAALEN4CkKxkcwyDgCAVQhPQSjmk3FPXLYDACDwCE9ByPN8u0YqTwAABBzhKQjFRFB5AgDAKoSnIOSZKJOpCgAACDzCUxDiES0AAFiH8BSEeDgwAADWITwFISpPAABYh/AUhGIjmSQTAACrEJ6CkGeqAibJBAAg8AhPQYjKEwAA1iE8BaFoxjwBAGAZwlMQ8lSerlJ5AgAg4AhPQYgxTwAAWIfwFIQY8wQAgHUIT0GIeZ4AALAO4SkIMcM4AADWITwFIU/lqbG5RW63YXFvAAD4fCE8BaGYT8Y8GYb08TUu3QEAEEiEpyAUHRFu/tzIuCcAAAKK8BSEwsJsZvWpkekKAAAIKMJTkLp+xx2DxgEACCRLw9PevXuVl5en5ORk2Ww2bd++vV2bU6dOaerUqXI6nYqLi9PYsWNVVVXVrp1hGMrNzW23nfLyctlstg5fBw8eNNtVVVUpLy9PsbGxSkhI0MKFC9XU1OSP3fYJ8447whMAAAFlaXhqaGhQRkaGCgsLO1xfWVmprKwsDR48WOXl5Tp69KieeeYZRUVFtWu7efNm2Wy2dsszMzN14cKFNq9vfvObuuOOOzRq1ChJUktLi6ZMmaKGhgbt27dP27ZtU3FxsRYvXuzbHfYhs/LEZTsAAALKbuWX5+bmKjc3t9P1K1as0AMPPKC1a9eaywYMGNCu3dGjR7Vx40YdPHhQSUlJbdZFRkYqMTHRfN/c3KwdO3boiSeeMMNWaWmpTp48qerqaiUnJ0uSNmzYoHnz5mnVqlWKj4/vsH8ul0sul8t8X1dXdxN77RvMMg4AgDW67Zgnt9utkpISDRw4UDk5OerTp4/GjBnT7tJeY2OjZs+ercLCwjYhqTM7duzQX//6V82bN89cduDAAQ0dOtQMTpKUk5Mjl8ulw4cPd7qt1atXy+l0mq+UlBSv97OreL4dAADW6Lbh6eLFi6qvr9eaNWs0efJklZaWavr06ZoxY4b27NljtisoKFBmZqby8/NvaruvvvqqcnJy2gSdmpoa9e3bt027Xr16KTIyUjU1NZ1ua/ny5aqtrTVf1dXVXu5l18VEUHkCAMAKll62+yxut1uSlJ+fr4KCAknS8OHDtX//fhUVFWnixInasWOHysrKdOTIkZva5p/+9Cf9+te/1s9//vN26zoaL2UYRofLPRwOhxwOx019t6/FmAPGqTwBABBI3bbylJCQILvdrvT09DbLhwwZYt5tV1ZWpsrKSvXs2VN2u112e2sWnDlzpu65555229y6datuu+02TZ06tc3yxMTEdhWmy5cvq7m5uV1FqruI5eHAAABYotuGp8jISI0ePVqnT59us/zMmTNKS0uTJC1btkzHjh1TRUWF+ZKkTZs2aevWrW0+ZxiGtm7dqkceeUQRERFt1o0bN04nTpzQhQsXzGWlpaVyOBwaOXKkH/bu1sXwcGAAACxh6WW7+vp6nT171nx/7tw5VVRUqHfv3kpNTdXSpUs1a9YsTZgwQdnZ2dq5c6fefPNNlZeXS2qtGHU0SDw1NVX9+/dvs6ysrEznzp3TY4891q79pEmTlJ6erjlz5mjdunW6dOmSlixZovnz53d6p53VqDwBAGANSytPhw4d0ogRIzRixAhJ0qJFizRixAg9++yzkqTp06erqKhIa9eu1bBhw7RlyxYVFxcrKyvL6+969dVXlZmZqSFDhrRbFx4erpKSEkVFRWn8+PF66KGHNG3aNK1fv/7WdtCPYpiqAAAAS9gMwzCs7kSoqKurk9PpVG1trd8rVv/fe1Va/ovj+sqQvtoyd5RfvwsAgFDm7d/vbjvmCZ+NyhMAANYgPAUpz+NZmKoAAIDAIjwFKR7PAgCANQhPQYrHswAAYA3CU5Ci8gQAgDUIT0HKrDwx5gkAgIAiPAUpT+Wp6ZpbzS1ui3sDAMDnB+EpSHnutpO44w4AgEAiPAWpSHuY7GE2SYx7AgAgkAhPQez6RJlUngAACBTCUxCL/WTQeCPTFQAAEDCEpyDmqTw1cNkOAICAITwFMbPyRHgCACBgCE9BzKw8cdkOAICAITwFsdhIKk8AAAQa4SmI8Xw7AAACj/AUxGIiWi/bXW0mPAEAECiEpyAW4/CMeeKyHQAAgUJ4CmLXxzxReQIAIFAIT0GMyhMAAIFHeApiVJ4AAAg8wlMQY4ZxAAACj/AUxHi2HQAAgUd4CmLRVJ4AAAg4wlMQ84x5usqYJwAAAobwFMQY8wQAQOARnoIYY54AAAg8wlMQi/1U5ckwDIt7AwDA5wPhKYh5HgzsNiTXNbfFvQEA4POB8BTEoj95MLDELOMAAAQK4SmIhYfZzADFLOMAAAQG4SnIee64IzwBABAYhKcgZz4cmOkKAAAICMJTkDMfDsx0BQAABAThKcgxUSYAAIFFeApy5kSZhCcAAALC6/DU3Nys7OxsnTlzxh/9gZfMyhOX7QAACAivw1NERIROnDghm83mj/7AS+aYJypPAAAERJcu2z3yyCN69dVXfd0XdEE0lScAAAKqS+GpqalJL7/8skaOHKlvf/vbWrRoUZvXzdq7d6/y8vKUnJwsm82m7du3t2tz6tQpTZ06VU6nU3FxcRo7dqyqqqratTMMQ7m5uZ1up6SkRGPGjFF0dLQSEhI0Y8aMNuurqqqUl5en2NhYJSQkaOHChWpqarrpfbGKZ8zT1WbCEwAAgWDvyodOnDihu+66S5LajX3y5nJeQ0ODMjIy9I1vfEMzZ85st76yslJZWVl67LHH9L3vfU9Op1OnTp1SVFRUu7abN2/u9LuLi4s1f/58/eAHP9C9994rwzB0/Phxc31LS4umTJmi22+/Xfv27dNHH32kuXPnyjAM/fCHP7zp/bHC9TFPXLYDACAQuhSedu/e7ZMvz83NVW5ubqfrV6xYoQceeEBr1641lw0YMKBdu6NHj2rjxo06ePCgkpKS2qy7du2annzySa1bt06PPfaYuXzQoEHmz6WlpTp58qSqq6uVnJwsSdqwYYPmzZunVatWKT4+vsP+uVwuuVwu831dXd0N9tj3ro95ovIEAEAg3PJUBX/605/05z//2Rd9acPtdqukpEQDBw5UTk6O+vTpozFjxrS7JNfY2KjZs2ersLBQiYmJ7bbz+9//Xn/+858VFhamESNGKCkpSbm5uXr//ffNNgcOHNDQoUPN4CRJOTk5crlcOnz4cKd9XL16tZxOp/lKSUm59R33kjnDOJUnAAACokvhye126/nnn5fT6VRaWppSU1PVs2dPvfDCC3K73T7p2MWLF1VfX681a9Zo8uTJKi0t1fTp0zVjxgzt2bPHbFdQUKDMzEzl5+d3uJ0PP/xQkrRy5Up997vf1VtvvaVevXpp4sSJunTpkiSppqZGffv2bfO5Xr16KTIyUjU1NZ32cfny5aqtrTVf1dXVt7rbXqPyBABAYHXpst2KFSv06quvas2aNRo/frwMw9D//M//aOXKlfr444+1atWqW+6YJ4Tl5+eroKBAkjR8+HDt379fRUVFmjhxonbs2KGysjIdOXLkhttZsWKFOa5q69at6tevn/7rv/5L3/72tyV1PFbLMIzPHMPlcDjkcDi6toM+wgzjAAAEVpfC0+uvv64tW7Zo6tSp5rKMjAx94Qtf0IIFC3wSnhISEmS325Went5m+ZAhQ7Rv3z5JUllZmSorK9WzZ882bWbOnKm7775b5eXl5hioT2/H4XBowIAB5l17iYmJ+t3vftdmG5cvX1Zzc3O7ilR3Y84wzlQFAAAERJcu2126dEmDBw9ut3zw4MHmpbBbFRkZqdGjR+v06dNtlp85c0ZpaWmSpGXLlunYsWOqqKgwX5K0adMmbd26VZI0cuRIORyONttpbm7WH/7wB3M748aN04kTJ3ThwgWzTWlpqRwOh0aOHOmT/fEXzzxPjc1UngAACIQuVZ4yMjJUWFioF198sc3ywsJCZWRk3PR26uvrdfbsWfP9uXPnVFFRod69eys1NVVLly7VrFmzNGHCBGVnZ2vnzp168803VV5eLqm1YtTRIPHU1FT1799fkhQfH6/HH39czz33nFJSUpSWlqZ169ZJkr72ta9JkiZNmqT09HTNmTNH69at06VLl7RkyRLNnz+/0zvtugtzzBOVJwAAAqJL4Wnt2rWaMmWKfvOb32jcuHGy2Wzav3+/qqur9fbbb9/0dg4dOqTs7GzzvWeCzblz5+q1117T9OnTVVRUpNWrV2vhwoUaNGiQiouLlZWV5VV/161bJ7vdrjlz5ujq1asaM2aMysrK1KtXL0lSeHi4SkpKtGDBAo0fP17R0dF6+OGHtX79eq++xwqMeQIAILBshmEYXfng+fPn9dJLL+l///d/ZRiG0tPTtWDBgja3+3/e1NXVyel0qra2NmAVq0sNTbrrhV2SpMofPKDwMJ45CACAN7z9++115am5uVmTJk3Sj3/8Y58MDMet8VSepNaHA8dFRVjYGwAAQp/XA8YjIiJ04sQJrx7DAv9x2MPMahNzPQEA4H9dutvukUce0auvvurrvqALbDYbz7cDACCAujRgvKmpSVu2bNGuXbs0atQoxcbGtlm/ceNGn3QONycmMlxXPr5G5QkAgADoUng6ceKE7rrrLkmt8y59GpfzAq91ugIX4QkAgADwOjy1tLRo5cqVGjZsmHr37u2PPsFL5sOBma4AAAC/83rMU3h4uHJyclRbW+uP/qALYpgoEwCAgOnSgPFhw4bpww8/9HVf0EWxTJQJAEDAdCk8rVq1SkuWLNFbb72lCxcuqK6urs0LgRVjPhyY8AQAgL91acD45MmTJUlTp05tM0DcMAzZbDa1tHD5KJCuV5447gAA+FuXwtPu3bt93Q/cAnPME5ftAADwuy5dtps4caLCwsL0yiuvaNmyZbrzzjs1ceJEVVVVKTw8/MYbgE95JslkqgIAAPyvS+GpuLhYOTk5io6O1pEjR+RyuSRJV65c0Q9+8AOfdhA3FuvgbjsAAAKlS+Hp+9//voqKivTKK68oIuL6g2gzMzP1+9//3medw82J4W47AAACpkvh6fTp05owYUK75fHx8frb3/52q32Cl2LNMU9UngAA8LcuhaekpCSdPXu23fJ9+/ZpwIABt9wpeMecYZypCgAA8Lsuhadvf/vbevLJJ/W73/1ONptN58+f189+9jMtWbJECxYs8HUfcQNUngAACJwuTVXw1FNPqba2VtnZ2fr44481YcIEORwOLVmyRE888YSv+4gbYMwTAACB06XwJLXOMr5ixQqdPHlSbrdb6enp6tGjhy/7hpvE3XYAAAROl8OTJMXExGjUqFG+6gu6KNqc54nKEwAA/talMU/oXj495skwDIt7AwBAaCM8hQDP3XbX3IaaWtwW9wYAgNBGeAoBMRHXH4nDuCcAAPyL8BQC7OFhcthbf5XccQcAgH8RnkKEeccdcz0BAOBXhKcQYc71xCzjAAD4FeEpRHjC01UqTwAA+BXhKUTEfDJdQQPhCQAAvyI8hYhYBxNlAgAQCISnEGFWnpiqAAAAvyI8hYhYHtECAEBAEJ5CRIyDyhMAAIFAeAoRVJ4AAAgMwlOIuH63HeEJAAB/IjyFiBiz8sRlOwAA/InwFCI8Y554MDAAAP5FeAoRnjFPXLYDAMC/CE8hwjPmict2AAD4F+EpRHhmGOfBwAAA+Jel4Wnv3r3Ky8tTcnKybDabtm/f3q7NqVOnNHXqVDmdTsXFxWns2LGqqqpq184wDOXm5na4nTvuuEM2m63Na9myZW3aVFVVKS8vT7GxsUpISNDChQvV1NTky931KypPAAAEht3KL29oaFBGRoa+8Y1vaObMme3WV1ZWKisrS4899pi+973vyel06tSpU4qKimrXdvPmzbLZbJ1+1/PPP6/58+eb73v06GH+3NLSoilTpuj222/Xvn379NFHH2nu3LkyDEM//OEPb3EvA4Nn2wEAEBiWhqfc3Fzl5uZ2un7FihV64IEHtHbtWnPZgAED2rU7evSoNm7cqIMHDyopKanDbcXFxSkxMbHDdaWlpTp58qSqq6uVnJwsSdqwYYPmzZunVatWKT4+vsPPuVwuuVwu831dXV2n++JvMRFUngAACIRuO+bJ7XarpKREAwcOVE5Ojvr06aMxY8a0uyTX2Nio2bNnq7CwsNNwJEn/8R//odtuu03Dhw/XqlWr2lySO3DggIYOHWoGJ0nKycmRy+XS4cOHO93m6tWr5XQ6zVdKSkrXd/gWxTiuz/PkdhuW9QMAgFDXbcPTxYsXVV9frzVr1mjy5MkqLS3V9OnTNWPGDO3Zs8dsV1BQoMzMTOXn53e6rSeffFLbtm3T7t279cQTT2jz5s1asGCBub6mpkZ9+/Zt85levXopMjJSNTU1nW53+fLlqq2tNV/V1dW3sMe3JjbyehHxajPVJwAA/MXSy3afxe12S5Ly8/NVUFAgSRo+fLj279+voqIiTZw4UTt27FBZWZmOHDnymdvyfF6SvvzlL6tXr1766le/alajJHU4XsowjM8cR+VwOORwOLzeN3+IigiTzSYZRutcT7GObvurBQAgqHXbylNCQoLsdrvS09PbLB8yZIh5t11ZWZkqKyvVs2dP2e122e2tgWHmzJm65557Ot322LFjJUlnz56VJCUmJrarMF2+fFnNzc3tKlLdlc1mM6tPzDIOAID/dNvwFBkZqdGjR+v06dNtlp85c0ZpaWmSpGXLlunYsWOqqKgwX5K0adMmbd26tdNteypVnsHl48aN04kTJ3ThwgWzTWlpqRwOh0aOHOnL3fKrGGYZBwDA7yy9tlNfX29WfyTp3LlzqqioUO/evZWamqqlS5dq1qxZmjBhgrKzs7Vz5069+eabKi8vl9RaMepokHhqaqr69+8vqXUw+Lvvvqvs7Gw5nU4dPHhQBQUFmjp1qlJTUyVJkyZNUnp6uubMmaN169bp0qVLWrJkiebPn9/pnXbdUazDLl1xcccdAAB+ZGl4OnTokLKzs833ixYtkiTNnTtXr732mqZPn66ioiKtXr1aCxcu1KBBg1RcXKysrKyb/g6Hw6E33nhD3/ve9+RyuZSWlqb58+frqaeeMtuEh4erpKRECxYs0Pjx4xUdHa2HH35Y69ev993OBoBZeWKWcQAA/MZmGAb3tftIXV2dnE6namtrLalYfa1ovw7+4bJe/qe7lDus4/muAABAW97+/e62Y57gPc8jWhq4bAcAgN8QnkIIj2gBAMD/CE8hxKw8MVUBAAB+Q3gKIbGRVJ4AAPA3wlMIiXFQeQIAwN8ITyGEyhMAAP5HeAoh0Z7Hs3C3HQAAfkN4CiFUngAA8D/CUwhhzBMAAP5HeAohVJ4AAPA/wlMIYYZxAAD8j/AUQswZxnkwMAAAfkN4CiFUngAA8D/CUwjh2XYAAPgf4SmExES0Vp6aWww1XXNb3BsAAEIT4SmERH9yt50kXeXSHQAAfkF4CiGR9jBFhrf+Shu4dAcAgF8QnkJMDOOeAADwK8JTiImNZJZxAAD8ifAUYmI+GffEZTsAAPyD8BRiPM+3a6TyBACAXxCeQoz5fLtmwhMAAP5AeAoxnst2PKIFAAD/IDyFGB7RAgCAfxGeQgwPBwYAwL8ITyGGyhMAAP5FeAox5oBxpioAAMAvCE8hxjNVAZNkAgDgH4SnEEPlCQAA/yI8hZjoT8Y8NTLmCQAAvyA8hRgqTwAA+BfhKcQw5gkAAP8iPIUYKk8AAPgX4SnEMM8TAAD+RXgKMcwwDgCAfxGeQoyn8tTY3CLDMCzuDQAAoYfwFGI8lSfDkD5udlvcGwAAQg/hKcRE2cPNnxsYNA4AgM8RnkJMWJhNMZ477piuAAAAn7M0PO3du1d5eXlKTk6WzWbT9u3b27U5deqUpk6dKqfTqbi4OI0dO1ZVVVXt2hmGodzc3E63I0kul0vDhw+XzWZTRUVFm3VVVVXKy8tTbGysEhIStHDhQjU1NflgLwPv+h13VJ4AAPA1S8NTQ0ODMjIyVFhY2OH6yspKZWVlafDgwSovL9fRo0f1zDPPKCoqql3bzZs3y2azfeb3PfXUU0pOTm63vKWlRVOmTFFDQ4P27dunbdu2qbi4WIsXL+7ajlnMvOOO8AQAgM/Zrfzy3Nxc5ebmdrp+xYoVeuCBB7R27Vpz2YABA9q1O3r0qDZu3KiDBw8qKSmpw2298847Ki0tVXFxsd55550260pLS3Xy5ElVV1eb4WrDhg2aN2+eVq1apfj4+A636XK55HK5zPd1dXWd72wAmZUnLtsBAOBz3XbMk9vtVklJiQYOHKicnBz16dNHY8aMaXdJrrGxUbNnz1ZhYaESExM73Nb//d//af78+frpT3+qmJiYdusPHDigoUOHtqlK5eTkyOVy6fDhw532cfXq1XI6neYrJSWlazvrY8wyDgCA/3Tb8HTx4kXV19drzZo1mjx5skpLSzV9+nTNmDFDe/bsMdsVFBQoMzNT+fn5HW7HMAzNmzdPjz/+uEaNGtVhm5qaGvXt27fNsl69eikyMlI1NTWd9nH58uWqra01X9XV1V3YU9/j+XYAAPiPpZftPovb3TpHUX5+vgoKCiRJw4cP1/79+1VUVKSJEydqx44dKisr05EjRzrdzg9/+EPV1dVp+fLln/l9HY2XMgzjM8dRORwOORyOm9mdgIqJ+KTy1Ex4AgDA17pt5SkhIUF2u13p6eltlg8ZMsS8266srEyVlZXq2bOn7Ha77PbWLDhz5kzdc889Zpt3331XDodDdrtdd955pyRp1KhRmjt3riQpMTGxXYXp8uXLam5ubleRCgYxPKIFAAC/6baVp8jISI0ePVqnT59us/zMmTNKS0uTJC1btkzf/OY326wfNmyYNm3apLy8PEnSiy++qO9///vm+vPnzysnJ0dvvPGGxowZI0kaN26cVq1apQsXLpgDzktLS+VwODRy5Ei/7aO/xPJwYAAA/MbS8FRfX6+zZ8+a78+dO6eKigr17t1bqampWrp0qWbNmqUJEyYoOztbO3fu1Jtvvqny8nJJrRWjjgaJp6amqn///ubPn9ajRw9J0he/+EX169dPkjRp0iSlp6drzpw5WrdunS5duqQlS5Zo/vz5nd5p151ReQIAwH8svWx36NAhjRgxQiNGjJAkLVq0SCNGjNCzzz4rSZo+fbqKioq0du1aDRs2TFu2bFFxcbGysrJ82o/w8HCVlJQoKipK48eP10MPPaRp06Zp/fr1Pv2eQKHyBACA/9gMwzCs7kSoqKurk9PpVG1traUVqy2//VDfLzml/OHJ+s+vj7CsHwAABANv/3532wHj6LpYpioAAMBvCE8hyPNg4KvNjHkCAMDXCE8hiMezAADgP4SnEMTjWQAA8B/CUwji8SwAAPgP4SkEUXkCAMB/CE8hyKw8Mc8TAAA+R3gKQZ7KU9M1t5pb3Bb3BgCA0EJ4CkGeu+0kqZHqEwAAPkV4CkGR9jDZw2ySpKuEJwAAfIrwFKI8E2U2MGgcAACfIjyFKM8jWhqZrgAAAJ8iPIUoKk8AAPgH4SlEmZUnwhMAAD5FeApRZuWJy3YAAPgU4SlExUZSeQIAwB8ITyEqxrxsR+UJAABfIjyFqJgIz/PtCE8AAPgS4SlExTg8Y564bAcAgC8RnkLU9TFPVJ4AAPAlwlOIovIEAIB/EJ5CFJUnAAD8g/AUophhHAAA/yA8hSiebQcAgH8QnkKUp/LU2EzlCQAAXyI8haiYSCpPAAD4A+EpRDHmCQAA/yA8hSjGPAEA4B+EpxAV+6nKk2EYFvcGAIDQQXgKUZ4HA7sNyXXNbXFvAAAIHYSnEBX9yYOBJWYZBwDAlwhPISo8zGYGKGYZBwDAdwhPIcyc64nwBACAzxCeQpj5cGCmKwAAwGcITyEslokyAQDwOcJTCGOiTAAAfI/wFMLMiTIJTwAA+AzhKYSZlScu2wEA4DOEpxBmjnmi8gQAgM9YGp727t2rvLw8JScny2azafv27e3anDp1SlOnTpXT6VRcXJzGjh2rqqqqdu0Mw1Bubm6H25k6dapSU1MVFRWlpKQkzZkzR+fPn2/TpqqqSnl5eYqNjVVCQoIWLlyopqYmX+5uwHnutmOqAgAAfMfS8NTQ0KCMjAwVFhZ2uL6yslJZWVkaPHiwysvLdfToUT3zzDOKiopq13bz5s2y2Wwdbic7O1s///nPdfr0aRUXF6uyslJf/epXzfUtLS2aMmWKGhoatG/fPm3btk3FxcVavHixb3bUIjFm5YnwBACAr9it/PLc3Fzl5uZ2un7FihV64IEHtHbtWnPZgAED2rU7evSoNm7cqIMHDyopKand+oKCAvPntLQ0LVu2TNOmTVNzc7MiIiJUWlqqkydPqrq6WsnJyZKkDRs2aN68eVq1apXi4+M77J/L5ZLL5TLf19XV3XinA+j6mCcu2wEA4CvddsyT2+1WSUmJBg4cqJycHPXp00djxoxpd0musbFRs2fPVmFhoRITE2+43UuXLulnP/uZMjMzFRERIUk6cOCAhg4dagYnScrJyZHL5dLhw4c73dbq1avldDrNV0pKStd21k9iqTwBAOBz3TY8Xbx4UfX19VqzZo0mT56s0tJSTZ8+XTNmzNCePXvMdgUFBcrMzFR+fv5nbu/f//3fFRsbq9tuu01VVVX61a9+Za6rqalR375927Tv1auXIiMjVVNT0+k2ly9frtraWvNVXV3dxb31D3OGcSpPAAD4TLcNT263W5KUn5+vgoICDR8+XMuWLdODDz6ooqIiSdKOHTtUVlamzZs333B7S5cu1ZEjR1RaWqrw8HA98sgjMgzDXN/ReCnDMDodRyVJDodD8fHxbV7dCZUnAAB8r9uGp4SEBNntdqWnp7dZPmTIEPNuu7KyMlVWVqpnz56y2+2y21vDwsyZM3XPPfe0297AgQN1//33a9u2bXr77bf17rvvSpISExPbVZguX76s5ubmdhWpYMIM4wAA+F63DU+RkZEaPXq0Tp8+3Wb5mTNnlJaWJklatmyZjh07poqKCvMlSZs2bdLWrVs73ban4uQZ7D1u3DidOHFCFy5cMNuUlpbK4XBo5MiRvtytgPLMMH6VyhMAAD5j6d129fX1Onv2rPn+3LlzqqioUO/evZWamqqlS5dq1qxZmjBhgrKzs7Vz5069+eabKi8vl9RaMepokHhqaqr69+8vSXrvvff03nvvKSsrS7169dKHH36oZ599Vl/84hc1btw4SdKkSZOUnp6uOXPmaN26dbp06ZKWLFmi+fPnd7tLcd6IpvIEAIDPWVp5OnTokEaMGKERI0ZIkhYtWqQRI0bo2WeflSRNnz5dRUVFWrt2rYYNG6YtW7aouLhYWVlZN/0d0dHR+sUvfqH77rtPgwYN0qOPPqqhQ4dqz549cjgckqTw8HCVlJQoKipK48eP10MPPaRp06Zp/fr1vt/pADLHPPF4FgAAfMZmfHrUNG5JXV2dnE6namtru0XFqvpSo+5eu1tREWH63xc6n08LAIDPM2//fnfbMU+4dZ4xTx83u9XiJiMDAOALhKcQ5rnbTuLhwAAA+ArhKYQ57GEKD2udp4q5ngAA8A3CUwiz2Ww83w4AAB8jPIU4ZhkHAMC3CE8hzlN5IjwBAOAbhKcQZz4cmAHjAAD4BOEpxMUwUSYAAD5FeApxsTyiBQAAnyI8hbgYh6fyRHgCAMAXCE8h7nrlict2AAD4AuEpxHnGPF0lPAEA4BOEpxAXw5gnAAB8ivAU4mId3G0HAIAvEZ5CHJUnAAB8i/AU4ng8CwAAvmW3ugPwL88M4xXVf9PjPz0se7hNEeFhigi3yR4epoiwT/71LAsL+6RNaztPG5ut9UHDYTabbJLCwqQwm01S679httY2YZ+0s3mWh0mt7yTZJJuur7eZiz/ZvtmmdYXtU+3Vpr3avJfarzc/83fHw/apBbZPrbX9fcMbLO9oGzf7+Q6XdbCdG3/3DdZ32ODmvudG2/Yn2412/Eafv6XvvqWvviU3Opf8/v3Wfj0CLJh/333joxQRbm3th/AU4r7QM1qSdKmhSTvfr7G4NwAA3JqyxRM14PYelvaB8BTihqf01E8f+0f9+fJVNbsNXWtxq7nFreYWQ9daDF1zt/7c3OJuXfdJm2sthpo++fea2y3DkAxJbsOQ25AMw5BheN63LtPfvTckud2GJMlQa3vPdgzDMPvYusxot84w/2P+0/Zzn/q85zvavL/etI022+9kG5/1+ZvV0fY7Xtt+/S1+dZvj9Fnb7GgfO/psoNzwm2/QwLqed/Pj1o1ZeNhuiRHUR906vvh932p12hcITyHOZrPp7n+43epuAAAQMhgwDgAA4AXCEwAAgBcITwAAAF4gPAEAAHiB8AQAAOAFwhMAAIAXCE8AAABeIDwBAAB4gfAEAADgBcITAACAFwhPAAAAXiA8AQAAeIHwBAAA4AXCEwAAgBfsVncglBiGIUmqq6uzuCcAAOBmef5ue/6O3wjhyYeuXLkiSUpJSbG4JwAAwFtXrlyR0+m8YTubcbMxCzfkdrt1/vx5xcXFyWaz+Wy7dXV1SklJUXV1teLj43223VDHcesajpv3OGZdw3HrGo5b13zWcTMMQ1euXFFycrLCwm48oonKkw+FhYWpX79+ftt+fHw8/6N0Acetazhu3uOYdQ3HrWs4bl3T2XG7mYqTBwPGAQAAvEB4AgAA8ALhKQg4HA4999xzcjgcVnclqHDcuobj5j2OWddw3LqG49Y1vjxuDBgHAADwApUnAAAALxCeAAAAvEB4AgAA8ALhCQAAwAuEpyDwox/9SP3791dUVJRGjhyp3/72t1Z3qVtbuXKlbDZbm1diYqLV3epW9u7dq7y8PCUnJ8tms2n79u1t1huGoZUrVyo5OVnR0dG655579P7771vT2W7kRsdt3rx57c69sWPHWtPZbmL16tUaPXq04uLi1KdPH02bNk2nT59u04bzrb2bOW6cb+29/PLL+vKXv2xOhDlu3Di988475npfnWuEp27ujTfe0He+8x2tWLFCR44c0d13363c3FxVVVVZ3bVu7Utf+pIuXLhgvo4fP251l7qVhoYGZWRkqLCwsMP1a9eu1caNG1VYWKiDBw8qMTFR999/v/n8xs+rGx03SZo8eXKbc+/tt98OYA+7nz179uhf//Vf9e6772rXrl26du2aJk2apIaGBrMN51t7N3PcJM63v9evXz+tWbNGhw4d0qFDh3TvvfcqPz/fDEg+O9cMdGv/+I//aDz++ONtlg0ePNhYtmyZRT3q/p577jkjIyPD6m4EDUnGL3/5S/O92+02EhMTjTVr1pjLPv74Y8PpdBpFRUUW9LB7+vvjZhiGMXfuXCM/P9+S/gSLixcvGpKMPXv2GIbB+Xaz/v64GQbn283q1auXsWXLFp+ea1SeurGmpiYdPnxYkyZNarN80qRJ2r9/v0W9Cg4ffPCBkpOT1b9/f33961/Xhx9+aHWXgsa5c+dUU1PT5rxzOByaOHEi591NKC8vV58+fTRw4EDNnz9fFy9etLpL3Uptba0kqXfv3pI4327W3x83D863zrW0tGjbtm1qaGjQuHHjfHquEZ66sb/+9a9qaWlR37592yzv27evampqLOpV9zdmzBj95Cc/0a9//Wu98sorqqmpUWZmpj766COruxYUPOcW5533cnNz9bOf/UxlZWXasGGDDh48qHvvvVcul8vqrnULhmFo0aJFysrK0tChQyVxvt2Mjo6bxPnWmePHj6tHjx5yOBx6/PHH9ctf/lLp6ek+PdfsPust/MZms7V5bxhGu2W4Ljc31/x52LBhGjdunL74xS/q9ddf16JFiyzsWXDhvPPerFmzzJ+HDh2qUaNGKS0tTSUlJZoxY4aFPesennjiCR07dkz79u1rt47zrXOdHTfOt44NGjRIFRUV+tvf/qbi4mLNnTtXe/bsMdf74lyj8tSNJSQkKDw8vF0ivnjxYrvkjM7FxsZq2LBh+uCDD6zuSlDw3JnIeXfrkpKSlJaWxrkn6d/+7d+0Y8cO7d69W/369TOXc759ts6OW0c431pFRkbqzjvv1KhRo7R69WplZGToP//zP316rhGeurHIyEiNHDlSu3btarN8165dyszMtKhXwcflcunUqVNKSkqyuitBoX///kpMTGxz3jU1NWnPnj2cd1766KOPVF1d/bk+9wzD0BNPPKFf/OIXKisrU//+/dus53zr2I2OW0c43zpmGIZcLpdvzzUfDWaHn2zbts2IiIgwXn31VePkyZPGd77zHSM2Ntb4wx/+YHXXuq3Fixcb5eXlxocffmi8++67xoMPPmjExcVxzD7lypUrxpEjR4wjR44YkoyNGzcaR44cMf74xz8ahmEYa9asMZxOp/GLX/zCOH78uDF79mwjKSnJqKurs7jn1vqs43blyhVj8eLFxv79+41z584Zu3fvNsaNG2d84Qtf+Fwft3/5l38xnE6nUV5ebly4cMF8NTY2mm0439q70XHjfOvY8uXLjb179xrnzp0zjh07Zjz99NNGWFiYUVpaahiG7841wlMQeOmll4y0tDQjMjLSuOuuu9rcqor2Zs2aZSQlJRkRERFGcnKyMWPGDOP999+3ulvdyu7duw1J7V5z5841DKP19vHnnnvOSExMNBwOhzFhwgTj+PHj1na6G/is49bY2GhMmjTJuP32242IiAgjNTXVmDt3rlFVVWV1ty3V0fGSZGzdutVsw/nW3o2OG+dbxx599FHz7+Xtt99u3HfffWZwMgzfnWs2wzCMLlbCAAAAPncY8wQAAOAFwhMAAIAXCE8AAABeIDwBAAB4gfAEAADgBcITAACAFwhPAAAAXiA8AQAAeIHwBAB+Ul5eLpvNpr/97W9WdwWADxGeAAAAvEB4AgAA8ALhCUDIMgxDa9eu1YABAxQdHa2MjAz993//t6Trl9RKSkqUkZGhqKgojRkzRsePH2+zjeLiYn3pS1+Sw+HQHXfcoQ0bNrRZ73K59NRTTyklJUUOh0P/8A//oFdffbVNm8OHD2vUqFGKiYlRZmamTp8+7d8dB+BXhCcAIeu73/2utm7dqpdfflnvv/++CgoK9M///M/as2eP2Wbp0qVav369Dh48qD59+mjq1Klqbm6W1Bp6HnroIX3961/X8ePHtXLlSj3zzDN67bXXzM8/8sgj2rZtm1588UWdOnVKRUVF6tGjR5t+rFixQhs2bNChQ4dkt9v16KOPBmT/AfiHzTAMw+pOAICvNTQ0KCEhQWVlZRo3bpy5/Jvf/KYaGxv1rW99S9nZ2dq2bZtmzZolSbp06ZL69eun1157TQ899JD+6Z/+SX/5y19UWlpqfv6pp55SSUmJ3n//fZ05c0aDBg3Srl279JWvfKVdH8rLy5Wdna3f/OY3uu+++yRJb7/9tqZMmaKrV68qKirKz0cBgD9QeQIQkk6ePKmPP/5Y999/v3r06GG+fvKTn6iystJs9+lg1bt3bw0aNEinTp2SJJ06dUrjx49vs93x48frgw8+UEtLiyoqKhQeHq6JEyd+Zl++/OUvmz8nJSVJki5evHjL+wjAGnarOwAA/uB2uyVJJSUl+sIXvtBmncPhaBOg/p7NZpPUOmbK87PHp4v10dHRN9WXiIiIdtv29A9A8KHyBCAkpaeny+FwqKqqSnfeeWebV0pKitnu3XffNX++fPmyzpw5o8GDB5vb2LdvX5vt7t+/XwMHDlR4eLiGDRsmt9vdZgwVgNBH5QlASIqLi9OSJUtUUFAgt9utrKws1dXVaf/+/erRo4fS0tIkSc8//7xuu+029e3bVytWrFBCQoKmTZsmSVq8eLFGjx6tF154QbNmzdKBAwdUWFioH/3oR5KkO+64Q3PnztWjjz6qF198URkZGfrjH/+oixcv6qGHHrJq1wH4GeEJQMh64YUX1KdPH61evVoffvihevbsqbvuuktPP/20edlszZo1evLJJ/XBBx8oIyNDO3bsUGRkpCTprrvu0s9//nM9++yzeuGFF5SUlKTnn39e8+bNM7/j5Zdf1tNPP60FCxboo48+Umpqqp5++mkrdhdAgHC3HYDPJc+dcJcvX1bPnj2t7g6AIMKYJwAAAC8QngAAALzAZTsAAAAvUHkCAADwAuEJAADAC4QnAAAALxCeAAAAvEB4AgAA8ALhCQAAwAuEJwAAAC8QngAAALzw/wMU2yOTmgYFnQAAAABJRU5ErkJggg=="},"metadata":{}}]},{"cell_type":"code","source":"tp, tn, fp, fn = 0, 0, 0, 0\n\nfor input_data, label in train_loader:\n    if device:\n        input_data = input_data.to(device)\n        label = label.to(device)\n                \n    output = red(input_data)\n    output = torch.argmax(output, dim=1)\n\n    if label.item() == 1:\n        if output.item() == 1:\n            tp += 1\n        else:\n            fn += 1\n    else:\n        if output.item() == 1:\n            fp += 1\n        else:\n            tn += 1\n\nprint(tp, tn, fp, fn)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T16:39:31.954277Z","iopub.execute_input":"2023-05-30T16:39:31.954666Z","iopub.status.idle":"2023-05-30T16:41:31.859440Z","shell.execute_reply.started":"2023-05-30T16:39:31.954632Z","shell.execute_reply":"2023-05-30T16:41:31.858164Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"0 22973 0 7027\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}